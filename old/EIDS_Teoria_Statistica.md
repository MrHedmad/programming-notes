---
subtitle: Maria Teresa Giraudo
title: EIDS -- Teoria Statistica
---

# Table of Contents {#table-of-contents .TOC-Heading}

[Capitolo 1 -- Definizioni, tipi di esperimenti, campionamento.
[1](#_Toc3627459)](#_Toc3627459)

[Introduzione [1](#introduzione)](#introduzione)

[Tipologie di dati [1](#tipologie-di-dati)](#tipologie-di-dati)

[Tipologie di esperimento
[2](#tipologie-di-esperimento)](#tipologie-di-esperimento)

[Strategie di campionamento
[3](#strategie-di-campionamento)](#strategie-di-campionamento)

[Capitolo 2 - Analisi esplorativa dei dati: Statistica Descrittiva
[3](#capitolo-2---analisi-esplorativa-dei-dati-statistica-descrittiva)](#capitolo-2---analisi-esplorativa-dei-dati-statistica-descrittiva)

[Caratteristiche dei dati
[3](#caratteristiche-dei-dati)](#caratteristiche-dei-dati)

[Frequenze [4](#frequenze)](#frequenze)

[Rappresentazione grafica dei dati
[4](#rappresentazione-grafica-dei-dati)](#rappresentazione-grafica-dei-dati)

[Misure di centralità -- Come valutare il centro
[5](#misure-di-centralità-come-valutare-il-centro)](#misure-di-centralità-come-valutare-il-centro)

[Misure di dispersione -- Come valutare l'ampiezza della distribuzione
[6](#misure-di-dispersione-come-valutare-lampiezza-della-distribuzione)](#misure-di-dispersione-come-valutare-lampiezza-della-distribuzione)

[Misure di posizione -- Dividere in parti la distribuzione di dati
[7](#misure-di-posizione-dividere-in-parti-la-distribuzione-di-dati)](#misure-di-posizione-dividere-in-parti-la-distribuzione-di-dati)

[Analisi esplorativa dei dati -- Trarre informazioni preliminari per uno
studio
[7](#analisi-esplorativa-dei-dati-trarre-informazioni-preliminari-per-uno-studio)](#analisi-esplorativa-dei-dati-trarre-informazioni-preliminari-per-uno-studio)

[Capitolo 3 -- Probabilità
[8](#capitolo-3-probabilità)](#capitolo-3-probabilità)

[Operazioni con le probabilità -- Probabilità di due eventi
[9](#operazioni-con-le-probabilità-probabilità-di-due-eventi)](#operazioni-con-le-probabilità-probabilità-di-due-eventi)

[Variabili Aleatorie [11](#variabili-aleatorie)](#variabili-aleatorie)

[Distribuzioni binomiali -- Vero o Falso
[11](#distribuzioni-binomiali-vero-o-falso)](#distribuzioni-binomiali-vero-o-falso)

[Distribuzione di Poisson -- Eventi rari
[12](#distribuzione-di-poisson-eventi-rari)](#distribuzione-di-poisson-eventi-rari)

[Distribuzione normale -- Campana di Gauss
[13](#distribuzione-normale-campana-di-gauss)](#distribuzione-normale-campana-di-gauss)

[Distribuzioni campionarie di una statistica
[13](#distribuzioni-campionarie-di-una-statistica)](#distribuzioni-campionarie-di-una-statistica)

[Proporzioni -Distribuzione campionaria di una proporzione
[14](#proporzioni--distribuzione-campionaria-di-una-proporzione)](#proporzioni--distribuzione-campionaria-di-una-proporzione)

[Il teorema del Limite Centrale
[15](#il-teorema-del-limite-centrale)](#il-teorema-del-limite-centrale)

[Accertare la normalità di una distribuzione
[16](#accertare-la-normalità-di-una-distribuzione)](#accertare-la-normalità-di-una-distribuzione)

[Capitolo 4 -- Stime con un campione
[16](#capitolo-4-stime-con-un-campione)](#capitolo-4-stime-con-un-campione)

[Stima delle proporzioni in una popolazione
[16](#stima-delle-proporzioni-in-una-popolazione)](#stima-delle-proporzioni-in-una-popolazione)

[Gli intervalli di confidenza
[17](#gli-intervalli-di-confidenza)](#gli-intervalli-di-confidenza)

[Stima della media di una popolazione
[18](#stima-della-media-di-una-popolazione)](#stima-della-media-di-una-popolazione)

[La deviazione standard è nota
[18](#la-deviazione-standard-è-nota)](#la-deviazione-standard-è-nota)

[La deviazione standard non è nota
[19](#la-deviazione-standard-non-è-nota)](#la-deviazione-standard-non-è-nota)

[Stima della varianza di una popolazione
[20](#stima-della-varianza-di-una-popolazione)](#stima-della-varianza-di-una-popolazione)

[Capitolo 5 -- Verifica di un'ipotesi
[21](#capitolo-5-verifica-di-unipotesi)](#capitolo-5-verifica-di-unipotesi)

[Prendere una decisione ed arrivare ad una conclusione
[23](#prendere-una-decisione-ed-arrivare-ad-una-conclusione)](#prendere-una-decisione-ed-arrivare-ad-una-conclusione)

[Errori durante lo svolgimento di un test d'ipotesi
[24](#errori-durante-lo-svolgimento-di-un-test-dipotesi)](#errori-durante-lo-svolgimento-di-un-test-dipotesi)

[Capitolo 6 -- Inferenza per due campioni
[25](#capitolo-6-inferenza-per-due-campioni)](#capitolo-6-inferenza-per-due-campioni)

[Inferenza su due proporzioni
[26](#inferenza-su-due-proporzioni)](#inferenza-su-due-proporzioni)

[Inferenza su due medie: campioni indipendenti
[26](#inferenza-su-due-medie-campioni-indipendenti)](#inferenza-su-due-medie-campioni-indipendenti)

[Inferenza su differenze per campioni appaiati
[28](#inferenza-su-differenze-per-campioni-appaiati)](#inferenza-su-differenze-per-campioni-appaiati)

[Confronto della variabilità in due campioni
[28](#confronto-della-variabilità-in-due-campioni)](#confronto-della-variabilità-in-due-campioni)

[Capitolo 7 -- Correlazione e regressione
[29](#capitolo-7-correlazione-e-regressione)](#capitolo-7-correlazione-e-regressione)

[La regressione [30](#la-regressione)](#la-regressione)

[Valori anomali e punti influenti. Minimi scarti quadrati
[31](#valori-anomali-e-punti-influenti.-minimi-scarti-quadrati)](#valori-anomali-e-punti-influenti.-minimi-scarti-quadrati)

[Capitolo 8 -- Analisi della varianza. Metodo ANOVA
[31](#capitolo-8-analisi-della-varianza.-metodo-anova)](#capitolo-8-analisi-della-varianza.-metodo-anova)

[ANOVA ad una via [32](#anova-ad-una-via)](#anova-ad-una-via)

[]{#_Toc3627459 .anchor}

# Capitolo 1 -- Definizioni, tipi di esperimenti, campionamento.

## Introduzione

La statistica studia gruppi ristretti di un gruppo più numeroso,
cercando di scoprire qualcosa riguardo a quest'ultimo. Introduciamo i
termini di dati, statistica, censimento, Campione e Popolazione:

-   I **dati** sono le osservazioni, cioè le misure, raccolte.

-   La **Statistica** consiste in metodologia per disegnare esperimenti,
    ricavare dati, e poi organizzarli e studiarli per ottenere e esporre
    risultati.

-   La **popolazione** è l'insieme completo di tutti gli elementi in
    oggetto di studio.

-   Un **censimento** è la raccolta di dati di ogni singolo elemento
    della popolazione.

-   Un **campione** è un "sotto collezione" di membri della popolazione.

Vedremo che la selezione di una popolazione campione è estremamente
importante per ottenere dei dati che, quando opportunamente manipolati,
portano a conclusioni significative. Una cattiva selezione del campione
porta molto probabilmente all'inutilità dei dati raccolti.

Possiamo avere due tipologie di dati, per differenziare se essi sono
riguardanti alla popolazione, o ad un campione:

-   Un **parametro** è una misura che descrive una caratteristica di
    un'intera popolazione.

-   Una **statistica** è una misura che descrive una caratteristica di
    un campione.

Potremmo avere, ad esempio, sia il parametro "media delle età" che la
statistica "media delle età". Proprio per la definizione di popolazione,
ottenere parametri è molto complesso se non impossibile. I metodi
statistici si basano su, utilizzando statistiche, inferire sul possibile
valore dei parametri.

## Tipologie di dati

Possiamo inoltre dividere i dati in base a di cosa sono costituiti:

-   I dati quantitativi sono numeri, e questi numeri sono il risultato
    di conteggi o misure.

    -   Ad esempio, Marco è alto 1.80 metri. Questo dato deriva da una
        misura diretta dell'altezza di Marco.

-   I dati qualitativi sono codici numerici o di caratteri, e si
    riferiscono a categorie distinte in base a caratteristiche non
    numeriche.

    -   Ad esempio, Marco è nato a Genova. Questo dato non arriva da una
        misura diretta, e ci dice soltanto che, qualitativamente, Marco
        è nato nella città "Genova".

Da non confondere dati numerici come sempre quantitativi: ad esempio, il
codice di immatricolazione "12345" non è un dato quantitativo, seppure
numerico. Molti studi usano numeri per semplificare i dati qualitativi
tabelle o raccolte di dati, ma questi numeri sono solo questo, codici.\
Ad esempio, uno studio sulla pressione potrebbe utilizzare "1" se il
paziente è affetto da ipertensione, o "0" se non lo è. In questo caso,
calcolare la media di questa statistica non avrebbe alcun senso.

Distinguiamo anche, tra i dati quantitativi, tra discreti e continui:

-   I **dati discreti** corrispondono a casi in cui il possibile valore
    misurato può prendere solo un numero finito, o numerabile, di
    possibilità.

    -   Ad esempio, "Uova deposte da galline in un giorno" è un dato
        discreto, dato che può prendere solo i valori della serie
        infinita, ma numerabile, 1, 2, 3, ... Notare che, ovviamente,
        una gallina non potrà deporre "500" uova, ma neanche "1.3".

-   I **dati continui** corrispondono a quei casi in cui i valori
    possibili sono *infiniti* (o meglio, di più dell'infinità
    numerabile), e corrispondono ad una qualche scala continua, che
    copre un intervallo di valori senza interruzioni.

    -   Ad esempio, "quantità di latte prodotta da una mucca" è un dato
        continuo, dato che può avere qualsiasi valore volumetrico
        positivo: 0, 0.00000...1, 0.00000...2, 1.2634..., etc.... Notare
        che, anche se in teoria il valore potrebbe avere un numero
        pressoché infinito di valori dopo la virgola, la sensibilità li
        limiterà sempre.

Possiamo inoltre dividere le variabili in quattro tipologie: nominali,
ordinali, intervallari e rapportabili:

-   Le **variabili nominali** sono variabili come il nome, una etichetta
    o una categoria. Questi dati non possono essere ordinati (se non in
    modo arbitrario).

    -   Ad esempio, le risposte ad un sondaggio (Si, No, Non so), i
        colori di una pianta di pisello...

-   Le **variabili ordinali** possono avere un ordine, ma le differenze
    tra i valori possono non essere calcolabili o non avere significato.

    -   Ad esempio, i voti di un esame: A, B, C... sono ordinabili, cioè
        A è prima di C, ma le differenze tra di loro non sono
        calcolabili: A - B non può essere calcolato.

    -   Oppure, la valutazione di aggressività come 1° più aggressivo,
        2° più aggressivo... Possiamo ordinarli, ma 2 -- 3 non ha
        significato: il cambiamento di aggressività tra il 1° e il 2°
        può essere diversa da quella del 2° e 3° e così via.

-   Le **variabili intervallari** sono come quelle ordinali, ma qui le
    differenze di valori hanno un significato. In queste variabili,
    però, non esiste uno 0 di riferimento.

    -   Temperature in celsius: tra 20 °C e 30 °C c'è una differenza,
        calcolabile, di 10°C. Tuttavia, 0 °C non è uno zero di
        riferimento, dato che è preso come convenzione. Dire, quindi,
        che 40 °C è *due volte più caldo* di 20 °C è sbagliato.

    -   Gli anni: 2012, 2013, 2014. Possiamo calcolare le differenze
        (2012 -- 2014 = 2 anni), ma l'anno "0" non significa "assenza di
        tempo".

-   Le **variabili rapportabili** sono come quelle intervallari, ma qui
    è presente uno zero di riferimento. Per queste, sia le differenze
    che i rapporti hanno un significato.

    -   Il peso di un oggetto, l'età di una persona...

## Tipologie di esperimento

Possiamo raccogliere i dati in due modi distinti:

-   Gli **studi osservativi** sono volti alla raccolta di dati da
    elementi, senza modificare nulla di quegli elementi.

    -   Ad esempio, un sondaggio di opinione.

    -   Uno studio osservativo si divide in:

        -   Studio **trasversale**, dove i dati sono raccolti tutti
            nello stesso momento.

        -   Studio **retrospettivo**, dove i dati sono riferiti al
            passato (e sono raccolti da archivi, sondaggi...)

        -   Studio **di prospettiva**, dove i dati sono riferiti al
            futuro (raccolti seguendo nel tempo gruppi che condividono
            caratteristiche simili, dette **coorti**)

-   Gli **studi pianificati**, invece, raccolgono dati da elementi dopo
    un *trattamento*.

    -   Ad esempio uno studio clinico.

Gli studi pianificati possono essere affetti dal cosiddetto
**confondimento**, cioè dalla mescolanza degli effetti di più variabili,
che rendono i dati inutilizzabili. Ad esempio: somministriamo un
vaccino, ma al tempo stesso variabili ambientali fanno scendere
l'infettività della malattia. Il calo di incidenza è dovuto al vaccino o
alla temperatura? In uno studio pianificato, quindi, è estremamente
importante mantenere tutte le variabili costanti tranne quelle misurate.

Si sono adottati vari metodi per controllare le variabili e saper
discernere tra gli effetti delle stesse:

-   **Cieco**. Spesso usati negli studi clinici per rimuovere la
    variabile dell'effetto placebo. Tutti gli individui sono
    somministrati una pastiglia, ma solo nel gruppo trattato è realmente
    presente il principio attivo, e i pazienti non ne sono al corrente.
    Il doppio cieco c'è quando sia i pazienti che i medici che li
    controllano non sanno se i pazienti hanno preso o meno il principio
    attivo.

-   **Blocchi**. Se si deve testare l'efficacia per uno o più
    trattamenti, e bene dividere il campione in blocchi con
    caratteristiche omogenee.

    -   Ad esempio, dividiamo il campione in blocchi "maschi" e
        "femmine", poi diamo il trattamento a metà maschi e metà
        femmine. Uno studio così è meglio preparato a capire le
        differenze di effetto del trattamento tra maschi e femmine.

-   **Randomizzazione.** Al momento di assegnare i trattamenti ai
    pazienti, è di buona norma utilizzare una selezione casuale.

-   **Dimensione campionaria.** Per minimizzare gli effetti che la
    naturale mutabilità dei singoli soggetti hanno nel mascherare il
    reale effetto del trattamento, è bene che il campione sia di grandi
    dimensioni.

-   **Opportuna selezione del campione.** Ancora più importante della
    grandezza del campione è il modo in cui questo campione è
    selezionato. Le modalità più appropriate per selezionare un campione
    sono descritte più avanti.

## Strategie di campionamento

Se un campione non è opportunamente scelto, i dati prodotti possono
rivelarsi completamente inutilizzabili. Vediamo i metodi di
campionamento più comuni:

-   Un **campione casuale**, gli individui di una popolazione sono
    scelti in modo che **ciascun singolo individuo ha la stessa
    probabilità di essere selezionato**. Un **campione casuale
    semplice** è in campione id taglia *n* in cui ogni gruppo di
    individui di taglia *n* possibile ha la stessa possibilità di essere
    scelto.

    -   Il campionamento casuale semplice è da sempre il più adatto per
        ogni studio statistico, e porta ad avere risultati veramente
        inferibili sulla popolazione. È l'unico metodo utilizzato negli
        esempi da qui in avanti.

-   Il **campionamento sistematico** prevede la selezione di un punto
    iniziale e la successiva selezione di ogni individuo in posizione
    k-esima dal punto iniziale.

-   Nel **campionamento di convenienza** selezioniamo gli elementi per
    cui i dati sono facilmente raccoglibili.

-   Nel **campionamento stratificato** si suddivide la popolazione in
    gruppi per una o più caratteristiche, e poi si seleziona un campione
    da ogni sottogruppo.

-   Nel **campionamento a grappoli**, si suddivide la popolazione in
    sezioni, e le sezioni in gruppi, poi selezioniamo alcune sezioni, e
    poi alcuni gruppi in ciascuna sezione.

    -   Un campionamento a grappolo con molti stage di selezione è anche
        detto **multistage**.

È facile confondere c. a grappoli e c. stratificato. In quello a
grappoli, selezioniamo tutti gli individui da alcuni campioni di
popolazione, in quello a strati selezioniamo un campione di popolazione
da ciascuna categoria.

# Capitolo 2 - Analisi esplorativa dei dati: Statistica Descrittiva

In questo capitolo vedremo come analizzare i dati raccolti e ricavarne
alcune informazioni. Questa è detta statistica descrittiva, e non tenta
di inferire su parametri della popolazione, ma si limita a descrivere i
dati raccolti.

## Caratteristiche dei dati

-   Centro: è il valore rappresentativo o medio, che rappresenta il
    centro dei dati.

-   Variazione: una misura di dispersione dei dati.

-   Distribuzione: la forma della distribuzione dei dati (a campana,
    uniforme, asimmetrica, multimodale...)

-   Outlier: dati che si discostano particolarmente dalla maggioranza
    delle osservazioni.

-   Tempo: i cambiamenti dei dati nel tempo.

## Frequenze

In una **tabella delle frequenze** sono riportati i dati raccolti,
singoli o, più comunemente, divisi in categorie, assieme alle frequenze
i quali si sono presentati. Possiamo definire:

-   I **limiti inferiori delle classi** sono i valori più piccoli
    appartenenti a ciascuna classe.

-   I **limiti superiori delle classi** sono i valori più grandi
    appartenenti a ciascuna classe.

-   I **separatori di classe** sono valori calcolabili che separano
    ciascuna classe. Si sottraggono i limiti superiori ed inferiori, si
    divide per due, e si sottrare il valore ottenuto a ciascun limite
    inferiore.

-   I **punti medi** sono i valori centrali a ciascuna classe.

-   L'**ampiezza delle classi** è la differenza tra limiti inferiori di
    due classi successive.

Da notare che il numero di classi è di solito arbitrario, ma un buon
stimatore è $\sim\ \sqrt{(n)}$, e la larghezza delle classi è
$\sim\frac{(Valore\ massimo) - (Valore\ minimo)}{Numero\ di\ classi}$

Le **Frequenze relative** sono le frequenze di un certo parametro diviso
la taglia dei dati. La somma di tutte le frequenze relative deve dare 1,
quindi bisogna fare attenzione ad eventuali arrotondamenti.

Le **Frequenze cumulate** sono le frequenze che si trovano "accumulando"
via via le sequenze per ogni classe. La nuova tabella è, di solito,
"Meno di X", "Meno di Y" e così via. Si ottiene sommando le frequenze di
una classe con quelle della classe prima.

L'analisi delle frequenze è di solito la prima analisi che si fa di
qualche tipo di dato, e può produrre osservazioni interessanti (ad
esempio su come i dati sono stati raccolti, come nell'esempio dei
battiti al minuto, dove non ci sono valori dispari, e questo fa pensare
ad una raccolta di dati che è stata poi moltiplicata per 2 o per 4).

## Rappresentazione grafica dei dati

Per studiare una distribuzione, è utile produrre un grafico. Vediamo i
principali tipi di grafico che si usano per questo:

-   Un **istogramma** è un grafico a barre che riporta sull'asse
    orizzontale delle ascisse (*x*) le classi in cui sono stati
    suddivisi i dati, e sull'asse verticale delle ordinate (*y*) le
    frequenze (o le frequenze relative). L'area (l'altezza) delle barre
    corrisponde al valore di frequenze, e le barre sono disegnate
    adiacenti l'una all'altra (per far vedere una continuità).

-   Un **poligono delle frequenze** è una spezzata con in Y le
    frequenze, ed in x i punti medi delle classi. La linea spezzata è
    prolungata per toccare a sx e a dx l'asse delle ascisse.

-   Il **Grafico delle frequenze cumulate** o **grafico ad Ogiva** è una
    spzzata in cui sull'asse x sono presenti i separatori superiori di
    classe (e il separatore inferiore della prima classe), e sull'asse y
    le frequenze cumulate.

-   Un **dotplot** o **grafico a punti** è un grafico in cui ogni dato è
    rappresentato come un punto su di una scala graduata, e dati simili
    o uguali sono uno sopra l'altro.

-   Un **diagramma ramo-foglia** o ***stem-leaf plot*** è un grafico in
    cui i dati sono rappresentati elencando le cifre prima della virgola
    in ordine, e poi indicando, uno dopo l'altro, le cifre decimali di
    ogni dato in corrispondenza delle sue cifre prima della virgola.

-   I **Diagrammi di Pareto** sono diagrammi a barre utilizzati per dati
    qualitativi, con in ascissa le classi, ed in ordinata le frequenze.
    Le barre sono sempre ordinate in modo decrescente da sinistra.

-   I **Diagrammi a Torta** dividono l'area di un cerchio in spicchi,
    dove l'area di ogni spicchio è proporzionale alla frequenza (di
    solito la frequenza relativa).

-   I **Diagrammi a Dispersione** o **Scatterplot** sono diagrammi in
    cui ad ogni punto (x, y) corrispondono ad una coppia di dati per cui
    vogliamo cercare una correlazione.

> Esistono altri grafici, anche molto utili per alcune serie di dati, ma
> non sono affrontati qui. E' utile ricordare che un grafico non è un
> risultato in sé, ma meglio un modo per descrivere, esaminare e
> confrontare tra loro serie di dati.

## Misure di centralità -- Come valutare il centro

Una **misura di centralità** è un valore che si trova in qualche modo in
mezzo alla distribuzione. Vediamo le misure di centralità più
utilizzate:

-   **Media**: La media aritmetica è una delle più importanti misure di
    centralità. Con il termine "media" si intende la media aritmetica.
    La media artimetica è quel valore che si ottiene sommando tutti i
    valori edividendo per il numero di valori:

$$Media = \ \frac{\sum_{}^{}x}{n}$$

-   **Definizione dei simboli**:\
    $\sum_{}^{}x$ indica la somma di un insieme di dati.\
    x denota i singoli valori dell'insieme di dati.\
    n è il numero di valori in un campione\
    N è il numero di valori in una popolazione\
    $\bar{x} = \ \frac{\sum_{}^{}x}{n}$ è la media dei valori di un
    campione, o **media campionaria\
    **$\mu = \ \frac{\sum_{}^{}x}{N}$ è la media dei valori di una
    popolazione, anche chiamata solamente media.

```{=html}
<!-- -->
```
-   **Mediana**: La media è molto sensibile ai valori estremi della
    distribuzione. Per ovviare questo problema, si può trovare la
    mediana. La mediana di un insieme è il valore in posizione centrale
    (o la media dei valori in posizione centrale se n o N è dispari)
    dopo che i valori sono stati disposti in ordine crescente. È di
    solito indicata con $\widetilde{x}$.

    -   La mediana è più rappresentativa per insiemi con pochi dati
        molto alti o molto bassi.

-   **Moda**: La moda di un insieme di dati è il valore che si ripete
    più volte. È quindi il valore direttamente sotto il "picco" della
    distribuzione.

    -   Se una distribuzione ha due valori con la stessa frequenza
        massima, prende il nome di **bimodale**.

    -   Se una distribuzione ha più di due valori con la stessa
        frequenza massima, prende il nome di **multimodale**.

    -   Se una distribuzione non ha valori ripetuti, si dice che la
        distribuzione non ha moda.

    -   La moda non è molto usata per dati numerici, dato che spesso
        questi dati non hanno moda. È utile però per dati qualitativi
        come etichette o categorie.

-   **Midrange**: Il midrange è definito come la media dei valori
    massimo e minimo.

    -   È rarissimamente usato, proprio per la enorme sensibilità ai
        valori estremi. È da ricordare, però, perché è facile da
        calcolare, è utile per ricordare che ci sono molti modi per
        definire il centro di un insieme di dati, ed è spesso calcolato
        per sbaglio cercando la mediana.

Come regola generale di arrotondamento per questi calcoli, è utile
riportare una cifra decimale in più di quelle nei dati. Così, la media
di 2, 3 e 5 è 3.3.

Abbiamo anche altri modi per descrivere una distribuzione. Ne vediamo
due che ci possono essere utili in seguito:

-   **Media pesata** o **ponderata**: è usata quando i valori dei
    singoli dati possono avere diversa importanza, e volgiamo prendere
    in considerazione questo fatto nel calcolo della media.

    -   Se x è un valore, e w è il peso corrispondente al valore x,
        allora la media ponderata è:

> $$Media\ pesata = \ \frac{\sum_{}^{}(x*w)}{\sum_{}^{}w}\ $$

-   **Asimmetria (Skewness):** una distribuzione è detta asimmetrica
    quando si estende in modo diverso dall'una e dall'altra parte. È
    facilmente visibile con un grafico, ma si può anche vedere
    osservando media, mediana e moda. Una distribuzione è asimmetrica a
    sinistra quando la media e la mediana sono a sinistra della moda.
    Una distribuzione è asimmetrica a destra quando la media e la
    mediana sono a destra della moda. Se media, moda e mediana
    coincidono, la distribuzione è simmetrica. Si può calcolare il
    valore di asimmetria con la formula (in cui sigma è la deviazione
    standard, definita più avanti):

> $$SK = \ \frac{\sum_{}^{}\left( x\  - \ \overline{x} \right)^{3}}{n*\ \sigma^{3}}$$

-   **Curtosi**: La curtosi è la misura di quanto la distribuzione è
    appiattita o "acuta". La Normale gaussiana ha curtosi pari a zero.
    Essa si calcola con l'indice ρ (rho):

$$\rho = \ \frac{\sum_{}^{}\left( x\  - \ \ \overline{x} \right)^{4}}{n*\ \sigma^{4}}$$

## Misure di dispersione -- Come valutare l'ampiezza della distribuzione

La misura della dispersione di una serie di dati può essere molto utile
per trarre conclusioni che non sono efficacemente deducibili dal
semplice studio del centro. Vediamo alcuni indici utili per descrivere
la dispersione:

-   **Range**. Il range di una serie di dati è definito come il valore
    massimo meno il valore minimo. Come si nota, questo valore è poco
    significativo dato che è estremamente influenzato da valori estremi,
    e prende in considerazione solo due dati, magari in una collezione
    di molte osservazioni.

-   **Deviazione Standard**. La deviazione standard è la misura di
    dispersione più utile ed importante. Definisce la variazione dei
    singoli valori rispetto alla media. È definita come:

Per un campione:
$s = \ \sqrt{\frac{\sum_{}^{}\left( x - \overline{x} \right)^{2}}{n - 1}}$
oppure
$\ \sqrt{\frac{n\left( \sum_{}^{}x^{2} \right) - \left( \sum_{}^{}x \right)^{2}}{n(n - 1)}}$

Per una popolazione:
$\sigma = \ \sqrt{\frac{\sum_{}^{}(x - \mu)^{2}}{N}}$

Ove x sono i dati, n è la numerosità del campione, N è la grandezza
della popolazione, $\overline{x}$ è la media campionaria e μ è la media
della popolazione.

Notiamo che la deviazione standard non è mai negativa, ed è maggiore
maggiore è la dispersione dei dati. L'u.d.m. della deviazione standard è
identica a quella dei dati di partenza. La deviazione standard può anche
essere chiamata con SD (Standard Deviation).

Possiamo anche interpretare la deviazione standard con una semplice
regola empirica: Se la distribuzione di dati è a campana o simile ad una
a campana, circa 68% dei dati cadono entro 1 SD dalla media; circa 95%
dei dati cadono entro 2 SD dalla media, e il 99.7% dei dati cadono entro
3 SD dalla media.

Possiamo scomporre la formula della SD: innanzitutto, prende in
considerazione la cosiddetta **deviazione** di ogni singolo dato "x",
$x - \overline{x}$. Poi combina questi valori in un unico numero, ma la
semplice somma otterrebbe sempre 0. Per evitare che i dati negativi e
positivi si annullino, essi sono portati a valori positivi tramite
l'elevamento al quadrato. Nella SD, si applica la radice quadrata alla
fine di tutti gli altri calcoli per compensare l'elevamento al quadrato.
Semplicemente facendo la matrice della sommatoria della deviazione, e
dividendo per n ($\frac{\sum_{}^{}\left| x - \overline{x} \right|}{n}$),
otteniamo la cosiddetta **deviazione assoluta media.** Dividiamo per
$n - 1$ per meglio descrivere la sommatoria al numeratore: solo n -- 1
dati possono variare, dato che la media è fissata. Utilizzando n -- 1,
la varianza $s^{2}$ non sottostima sistematicamente la varianza di
popolazione (come vediamo qui sotto).

-   **Varianza**. La varianza di una serie di dati è definita come il
    quadrato della deviazione standard. Notare che la varianza
    campionaria è uno stimatore non distorto (cioè rappresenta bene,
    senza sovra o sotto-stimare) dellla varianza della popolazione.

    -   La varianza campionaria è $s^{2}$;

    -   La varianza della popolazione è $\sigma^{2}$

Dato che la varianza e la deviazione standard hanno la stessa unità di
misura dei dati, può risultare difficile confrontare dati di origine e
natura diversa. Per far questo, utilizziamo i **coefficienti di
variazione**, o **CV**.

-   Il **coefficiente di variazione** di una serie di dati è definito
    come la deviazione standard diviso la media in percentuale:

Per un campione: $CV = \ \frac{s}{\overline{x}}*100\%$ Per una
popolazione: $CV = \ \frac{\sigma}{\mu}*100\%$

## Misure di posizione -- Dividere in parti la distribuzione di dati

Può essere utile dividere in parti la distribuzione per proseguire con
la descrizione della distribuzione. Sono stati definiti alcuni valori
utili in questo senso:

-   **Quartili e percentili**. Come la mediana divide i valori
    esattamente a metà, i quartili la dividono in quarti. Definiamo tre
    quartili:

    -   $Q_{1}$, o Primo Quartile: Separa il 25% inferiore dal 75%
        superiore dei dati. (25% ≤ $Q_{1}$ ≤ 75%)

    -   $Q_{2}$, o Secondo Quartile: Coincide con la mediana, separa il
        50% inferiore dal superiore.

    -   $Q_{3}$, o Terzo Quartile: Separa il 75% inferiore dal 25%
        superiore dei dati. (75% ≤ $Q_{3}$ ≤ 25%)

    -   $Q_{4}$, o Quarto Quartile, non è definito, e coinciderebbe con
        tutto l'insieme dei dati.

Per il calcolo dei quartili, c'è discostanza. Programmi diversi infatti
producono risultati diversi.

-   Come per i quartili, possiamo dividere la distribuzione in 99
    **Percentili**, che dividono la serie di dati in 100 gruppi,
    ciascuno corrispondente all' 1% della distribuzione. Possiamo
    calcolare il percentile associato ad un certo dato x come:

$$P_{x} = \ \frac{numero\ di\ dati\ minori\ di\ x}{n}*100$$

-   I quartili coincidono con alcuni percentili, infatti
    $Q_{1} = \ P_{25}$, $Q_{2} = \ P_{50}$, $Q_{3} = \ P_{75}$ (e
    $Q_{3} = \ P_{100}$).

-   Utilizzando quartili e percentili, possiamo introdurre altre
    statistiche:

    -   Range interquartile: $Q_{3} - \ Q_{1}$

    -   Range semi-interquartile: $\frac{Q_{3} - \ Q_{1}}{2}$

    -   Midquartile: $\frac{Q_{3} + \ Q_{1}}{2}$

    -   Range Percentile 10-90: $P_{90} - \ P_{10}$

## Analisi esplorativa dei dati -- Trarre informazioni preliminari per uno studio

Riuscire a descrivere l'insieme di dati in un modo semplice ed efficace
per vedere come i dati sono formati. Con il termine **analisi
esplorativa dei dati** si intende l'uso di varie tecniche matematiche e
grafiche per chiarire la struttur dei dati.

Preliminarmente, è importante cercare eventuali valori che sono
ovviamente fuori dalla distribuzione di tutti gli altri dati. Questi
valori sono detti **outlier**. Gli outlier possono influire pesantemente
sulla media e sulla deviazione standard, o distorcere completamente un
istogramma.

![](media/image1.png){width="1.7225426509186352in"
height="2.0729418197725282in"}Alcuni Outlier sono frutto di errori:
misurazione, battitura... e devono essere trovati e rimossi prima di
continuare l'analisi. Altri outlier sono comunque valori corretti ma
molto rari: in una qualsiasi distribuzione è possibile avere un valore
ad esempio molto, molto grande, ma questo può essere molto improbabile.
È buona pratica includere questi tipi di Outlier, ma è bene effettuare
l'analisi sia utilizzandoli, sia escludendoli, per misurarne l'effetto.

Un grafico che bene esprime la forma dei dati è il **boxplot**, qui a
sinistra. I Boxplot che indicano anche gli outlier sono chiamati
**boxplot modificati**, mentre gli altri regolari.

È importante tenere a mente che i dati, oltre ad essere analizzati in
questo modo, sono da considerare criticamente: Qual è l'origine dei dai?
Il campione è scelto opportunamente? I dati sono stati raccolti
opportunamente? Cosa voglio capire da questi dati? Il campione è
abbastanza numeroso?\
Il pensiero critico è ugualmente importante al sapere maneggiare gli
strumenti statistici più matematici.

Con "**riassunto in cinque numeri**", si intende la panoramica che si
ottiene calcolando Minimo, $Q_{1}$, Mediana, $Q_{2}$ e Massimo. Per
un'analisi preliminare, è utile calcolare il riassunto in cinque numeri
assieme a Media e Deviazione standard.

# Capitolo 3 -- Probabilità 

Il calcolo delle probabilità è la base di tutti i metodi della
statistica inferenziale. Il calcolo della probabilità interessa tutti
gli eventi che sono casuali (aleatori), cioè non sono né certi né
impossibili. La possibilità (o probabilità) che un evento succeda è un
numero tra 0 e 1, dove 0 è l'impossibilità, e 1 è la certezza.

In statistica inferenziale, l'uso dello studio della probabilità può
portare ad pensare che una certa assunzione (ad esempio un ipotesi, o
spesso un evento complementare all'ipotesi) sia così improbabile da
essere sbagliata, o, al contrario così probabile da essere esatta.
Ovviamente, nella statistica una certezza perfetta non può verificarsi,
ma, con un piccolo margine di tolleranza per gli errori, i metodi della
statistica inferenziale sono alla basa di virtualmente qualsiasi studio
scientifico.

Possiamo riassumere il contenuto del paragrafo precedente con la
cosiddetta **legge degli eventi rari**: "*Se si è verificato un certo
evento e, in base ad un'ipotesi, la probabilità che questo evento si
verifichi è molto bassa, allora l'ipotesi è probabilmente errata*".

Iniziamo a definire alcuni termini utili nello studio delle probabilità:

-   Un **esperimento** è una azione, od un insieme di azioni, che
    portano alla produzione di dati.

    -   Ad esempio, il lancio di un dado (a sei facce) è un esperimento
        che porta alla produzione di un risultato ogni volta che è
        ripetuto.

-   Un **esito** è un singolo risultato di un esperimento.

    -   Nel lancio del dado, il singolo tiro risulta essere un 6. Questo
        è un esito.

-   Un **evento** è una raccolta di *esiti* di un esperimento.

    -   Nel lancio del dado, "Esce un numero pari" è un evento, composto
        dagli esiti 2, 4, 6.

-   Un **evento elementare** è un evento che non può essere suddiviso in
    eventi più semplici.

    -   "Esce un 3" è un evento elementare, mentre "Esce un numero
        dispari" non lo è (può essere diviso in 3 eventi più semplici,
        cioè "Esce 1", "Esce 3" ed "Esce 5")

-   Lo **spazio campionario** di un esperimento è l'insieme che contiene
    tutti i possibili esiti. Di solito è indicato con Ω.

    -   Nel lancio del dado, Ω = \[1, 2, 3, 4, 5, 6\]

-   **P** indica una probabilità. $P(X)\ $indica la probabilità
    dell'evento $X$.

-   $X$ (maiuscolo) indica una **variabile**. Una variabile è, in un
    esperimento, una caratteristica che è misurata.

-   $x$ (minuscolo) indica l'esito (numerico) di una variabile dopo che
    l'esperimento è stato effettuato.

> Ci sono vari modi per trovare la probabilità di un evento. I tre più
> importanti sono:

-   **Probabilità soggettiva**. P(A) viene stimata conoscendo tutte le
    circostanze significative sull'avvenimento di A. Questa è la
    probabilità meno affidabile, ma per eventi molto poco probabili, o
    molto probabili, questo calcolo può non essere molto discostante
    dalla realtà.

    -   Qual è la probabilità che un meteorite cada sulla mia macchina
        nel prossimo mese? Sapendo che i meteoriti cadono rarissimamente
        sulla terra, possiamo stimare che la P(x) sia molto, molto
        bassa, diciamo 1e-10.

-   **Probabilità classica**. Se tutti i possibili eventi sono
    equiprobabili, e conosciamo tutto lo spazio campionario, allora la
    probabilità esatta può essere semplicemente calcolata utilizzandola
    formula:

$$P(X) = \ \frac{ogni\ modo\ in\ cui\ x\ può\ verificarsi}{numero\ di\ eventi\ elementari} = \ \frac{s}{n}$$

-   **Approssimazione della probabilità con la frequenza relativa**. Se
    non conosciamo lo spazio campionario, o gli eventi non sono
    equiprobabili, allora possiamo calcolare la probabilità di un certo
    evento come:

$$P(X) = \ \frac{numero\ di\ volte\ in\ cui\ x\ si\ è\ verificato}{numero\ di\ ripetizioni\ dell^{'}esperimento}$$

Notare che all'aumentare delle ripetizioni dell'esperimento, la
probabilità con la frequenza relativa diventa sempre più uguale alla
probabilità reale (effettiva). Questo è detto **legge dei grandi
numeri**.

Se prendiamo in considerazione una variabile continua, essa può prendere
un numero infinito di valori, e ciascun valore avrà una probabilità
diversa di accadere. Possiamo quindi mostrare questa probabilità con una
funzione, chiamata **funzione di probabilità** o **curva di densità di
probabilità**, indicata con $f(X)$. Per trovare la probabilità che, ad
una certa ripetizione di un esperimento, *x* sia tra i valori a e b,
basta integrare la funzione di probabilità tra a e b:

$$P\lbrack a \leq x \leq b\rbrack = \int_{a}^{b}{f(X)} = F(x)$$

$F(x)$ è anche chiamata **funzione di distribuzione**. Notiamo due cose
da questa definizione:

1.  $P(a)$ è sempre pari a 0, proprio per la definizione di integrale
    definito.

2.  $P\lbrack - \infty \leq x \leq + \infty\rbrack$ è sempre pari ad 1
    (L'evento certo).

Per essere chiamata curva di densità, quindi, la funzione $f(x)$ deve
soddisfare due requisiti:

1.  L'area totale sottesa dalla curva è pari a 1, quindi c'è una
    relazione area/probabilità; e

2.  Ogni punto sulla curva deve essere ≥ a 0 (non esistono probabilità
    negative).

## Operazioni con le probabilità -- Probabilità di due eventi

**1. Eventi complementari**. A volte ci è utile sapere qual è la
probabilità che un evento A non accada. L'**evento complementare** di A,
indicato con $\overline{A}$, è un insieme dello spazio campionario che
contiene tutti gli esiti in cui A *non* si verifica. Possiamo calcolare
semplicemente la probabilità di $\overline{A}$ conoscendo $P(A)$:

$$P\left( \overline{A} \right) = 1 - P(A)$$

**2. Probabilità sommate.**
$\mathbf{P}\left( \mathbf{A}\mathbf{\ }\mathbf{o}\mathbf{\ }\mathbf{B} \right)\mathbf{,\ }\mathbf{P}\left( \mathbf{A}\mathbf{\cup}\mathbf{B} \right)$.
Possiamo chiederci quale sia la probabilità che avvenga l'evento A,
l'evento B, o entrambi. Questo è rappresentato dalle espressioni
$P(A\ o\ B)$ o $P(A \cup B)$. Per calcolarla, utilizziamo la **regola
della somma** dopo aver calcolato sia $P(A)$ che $P(B)$:

$$P(A \cup B) = P(A) + P(B) - P(A\ e\ B)$$

Dobbiamo rimuovere $P(A\ e\ B)$ perché, se non lo facessimo, conteremo
due volte gli eventi in cui A e B avvengono assieme. Nota che
$P(A\ e\ B)$ è anche indicato come $P(A \cap B)$.

**3. Probabilità prodotte.**
$\mathbf{P}\left( \mathbf{A \cap B} \right)$. Per calcolare la
probabilità che un evento A si verifichi contemporaneamente ad un evento
B (e questi due eventi sono indipendenti tra loro, vedi punto 4),
possiamo utilizzare la cosiddetta **regola del prodotto**:

$$P(A \cap B) = P(A)*P(B)$$

Questa regola è facilmente dimostrabile empiricamente: Prendiamo un test
formato da due domande, A e B. La prima (A) è una domanda Vero o Falso,
e la risposta esatta è Falso. La seconda domanda (B) è chiusa, con le
possibili risposte formate da a, b, c, d, e, in cui la risposta esatta è
la "c". Per calcolare la probabilità che, casualmente, uno studente
risponda in maniera corretta ad entrambe le domande, possiamo utilizzare
il metodo classico:

$$\Omega = \ \begin{bmatrix}
F,a & F,b & F,c & F,d & F,e \\
V,a & V,b & V,c & V,d & V,e \\
\end{bmatrix}$$

Notando che: $P(F) = \frac{1}{2}$ , $P(c) = \ \frac{1}{5}$ e
$P(F \cap c) = \ \frac{1}{10}$ ; salta subito all'occhio che
$P(F \cap c) = P(F)*P(c)$.

**4. Probabilità condizionata. B in seguito ad A.** Se un certo evento B
è condizionato dall'accadersi di un altro evento A, allora ci troviamo
davanti ad una probabilità condizionata: "B dato A" o $B|A$, quindi
$P\left( B \middle| A \right)$.

I due eventi, A e B, possono sia essere **dipendenti** tra di loro, cioè
che l'esito di uno influenze l'esito dell'altro, sia **indipendenti**,
cioè che l'accadere di uno non influenza l'altro.

Nel caso di due eventi **indipendenti**,
$P\left( B \middle| A \right) = P(B)$, dato che l'avvenire di A non ha
cambiato la probabilità dell'avvenire di B. L'esempio del paragrafo
precedente è del tipo indipendente.\
Nel caso di due eventi **dipendenti**, allora
$P\left( B \middle| A \right) \neq P(B)$, dato che, essendo già avvenuto
A, la probabilità di B cambia. Ad esempio, estraendo due numeri da una
scatola contenente tutti i numeri da 1 a 10 compresi, alla prima
estrazione, la probabilità di estrarre un numero particolare "a" dalla
scatola è $\frac{1}{10}$, mentre alla seconda estrazione lo spazio
campionario è cambiato, e la probabilità di estrarre un secondo numero
"b" diverso da "a" è $\frac{1}{9}$.

Nel calcolo di $P(A \cap B)$, se A e B sono **dipendenti** tra loro, non
è più corretto utilizzare la regola del prodotto vista prima, ma è
giusto usare la **regola formale del prodotto**:

$$P(A \cap B) = P(A)*P\left( B \middle| A \right)$$

La regola del prodotto è "estensibile" per più di due eventi, basta
moltiplicare via via tra loro tutti gli eventi interessati. Se gli
eventi sono tra loro dipendenti, allora la probabilità deve essere
opportunamente ritoccata per tutti gli eventi oltre al primo.

Notiamo che, negli esperimenti che riguardano l'estrazione di più
campioni, ci si potrebbe porre la domanda: "Estraendo più campioni
contemporaneamente, il secondo e successivi campioni sono realmente
scelti in modo casuale semplice?". La probabilità che un soggetto del
primo campione sia scelto per il secondo, proprio per il metodo di
campionamento, è 0. Questo influisce sulla casualità del campionamento,
come già detto essenziale per la significatività dei dati? In generale,
**se un campione rappresenta meno del 5% della popolazione**, la
probabilità che, potendo riselezionare gli individui, si selezioni di
nuovo un individuo già selezionato è così bassa che questo problema non
si pone, e le scelte successive possono essere considerate
**indipendenti** tra loro.

Come regola generale, possiamo definire anche matematicamente
$P\left( B \middle| A \right)$ con:\
$$P\left( B \middle| A \right) = \ \frac{P(A \cap B)}{P(A)}$$

Questa formula è utile se non conosciamo esattamente gli effetti di A su
B.

È importante sottolineare che le espressioni
$P\left( B \middle| A \right)$ e $P\left( A \middle| B \right)$ **non**
sono equivalenti.

**5. Regola del prodotto 2: "almeno uno"**. Potremmo volerci chiedere la
probabilità che almeno in una ripetizione dell'esperimento, l'evento A
avvenga. Per chiarirci, "Almeno uno" significa "uno o più", e il
complementare di "almeno uno" è "nessuno". Allora:

$$P("Almeno\ uno") = 1 - P\left( \text{nessuno} \right)$$

Possiamo calcolare facilmente la probabilità di "nessuno" con la regola
del prodotto. Ad esempio, la probabilità che su tre nascituri almeno uno
sia femmina è:

$$P("Almeno\ 1\ femmina") = \ 1 - P("Tre\ maschi")$$

$$P\left( \text{Tre\ Maschi} \right) = \ \frac{1}{2}*\frac{1}{2}*\frac{1}{2} = \ \frac{1}{8}$$

$$P("Almeno\ una\ femmina") = \ 1 - \ \frac{1}{8} = \ \frac{7}{8}$$

**6. Correggere la probabilità alla luce di nuove informazioni. Il
teorema di Bayes.** In un paese, il 51% delle persone sono uomini, e il
49% sono donne. Estraiamo a caso una persona che fuma il sigaro: Qual è
la probabilità che essa sia un uomo? Dato che non sappiamo se ci sono
relazioni tra fumare il sigaro e essere uomo, possiamo semplicemente
dire che la probabilità sia il 51%, uguale all'estrarre casualmente una
persona.

Successivamente, troviamo uno studio recente che dimostra che il 9.5%
dei maschi sono fumatori di sigaro, mentre solo l'1,5% delle femmine lo
sono. Ora potremmo voler cambiare la nostra probabilità alla luce di
questo nuovo fatto: per far ciò, utilizziamo il **teorema di Bayes**:

$$P\left( A \middle| B \right) = \ \frac{P(A)*P\left( B \middle| A \right)}{\left\lbrack P(A)*P\left( B \middle| A \right) \right\rbrack + \left\lbrack P\left( \overline{A} \right)*P\left( B \middle| \overline{A} \right) \right\rbrack}$$

Possiamo riassumere i nostri dati con:
$P(M) = 0.51;P\left( \overline{M} \right) = 0.49;P\left( S \middle| M \right) = 0.095;P\left( S \middle| \overline{M} \right) = 0.015$.
Applicando il teorema di Bayes, otteniamo 0.853, cioè la probabilità che
avendo selezionato un fumatore esso sia un uomo è 85,3%.

## Variabili Aleatorie

Iniziamo a definire cosa intendiamo con "variabile aleatoria":

-   Una **variabile aleatoria** è una variabile che assume un singolo
    valore numerico, determinato in base al caso, per ciascuno degli
    esiti dell'esperimento. Abbiamo già incontrato queste variabili
    nella sezione riguardante la probabilità.

    -   Una variabile aleatoria **continua** assume un numero infinito
        ed innumerabile di valori, associabili ad una scala continua,
        senza salti o interruzioni.

    -   Una variabile aleatoria **discreta** assume un numero finito o
        comunque numerabile di valori.

-   Una **distribuzione delle probabilità** è un grafico, tabella o
    funzione che fornisce la probabilità di ciascun valore della
    variabile aleatoria. Come abbiamo già visto prima, solo una funzione
    riesce a rappresentare in maniera sensibile una variabile aleatoria
    continua.

Un esempio di Distribuzione di probabilità è rappresentato
dall'**istogramma delle probabilità**, un istogramma in cui sull'asse
delle ascisse (x) sono mostrate le classi, mentre sull'asse delle
ordinate (y), sono mostrate le probabilità che il valore cada dentro
ognuna classe. Notare che l'area totale dell'istogramma è pari ad 1,
quindi $\sum_{}^{}{P(x) = 1}$, e che la probabilità di ogni possibile
valore di x è sempre compresa tra 0 ed 1.

Possiamo calcolare centro, variazione, distribuzione ed outlier anche
per questo tipo di dati:

-   Media della d.d.p:
    $\mu = \sum_{}^{}\left\lbrack x*P(x) \right\rbrack$

    -   Deriva da:
        $\mu = \ \frac{\sum_{}^{}(f*x)}{N} = \ \sum_{}^{}\left\lbrack \frac{f*x}{N} \right\rbrack$
        ma $\frac{f}{N} = P(x)$

-   Varianza della d.d.p:
    $\sigma^{2} = \sum_{}^{}\left\lbrack (x - \mu)^{2}*P(x) \right\rbrack$
    oppure
    $\sigma^{2} = \sum_{}^{}{\left\lbrack x^{2}*P(x) \right\rbrack - \mu^{2}}$

    -   Ottenuta in maniera simile alla media dalle formule di varianza
        e SD mostrate prima.

-   SD della d.d.p:
    $\sigma = \sqrt{\sum_{}^{}{\left\lbrack x^{2}*P(x) \right\rbrack - \mu^{2}}\ }$

{Ricordare: Potenze, poi moltiplicazioni, poi somme}

Vediamo di seguito alcune distribuzioni particolari che possono essere
utili nello studio delle probabilità di variabili aleatorie:

## Distribuzioni binomiali -- Vero o Falso

Quando trattiamo variabili con solo due possibili valori, ad esempio
Vero o Falso, oppure Si o No, siamo di fronte ad una **distribuzione
binomiale**.

-   Con **distribuzione binomiale** intendiamo la distribuzione che i
    dati presentano se:

    1.  L'esperimento a un numero fissato di prove;

    2.  Le singole prove sono indipendenti tra loro;

    3.  L'esito delle prove appartiene a solo due tipologie
        (dicotomico), ad esempio "risposta esatta" o "risposta
        sbagliata";

    4.  Le probabilità di ciascun risultato devono rimanere costanti tra
        prove diverse.

Alcuni simboli sono ricorrenti nelle distribuzioni binomiali:

-   S = Success e F = Failure indicano i due possibili esiti.

-   $P(S) = \ p$

-   $P(F) = \ q$, e quindi $q = 1 - p$

-   $n$ indica il numero di prove.

-   $x$ indica il numero di successi nelle $n\ $prove, quindi ha valori
    interi tra 0 e $n$ inclusi.

-   $P(x)$ indica la probabilità di avere $x$ successi in $n$ prove.

Notare che l'indicazione *successo* può denotare anche una cosa
negativa, in base a cosa stiamo considerando. Un errore comune è
confondere $x$ e $p$ con due categorie diverse.

Come abbiamo già visto, il punto 2. dei requisiti per una distribuzione
binomiale è rispettato anche in un campionamento senza reimmissione
purché il campione rappresenti meno del 5% della popolazione.

Per una distribuzione binomiale, possiamo calcolare $P(x)$ conoscendo
$p,\ q,\ x\ \text{ed}\ n$ utilizzando la **formula delle probabilità
binomiali**:

$$P(x) = \frac{n!}{(n - x)!*x!}*P^{x}*q^{n - x}$$

Questa formula tiene conto di tutte le possibili permutazioni delle
singole prove. Ad esempio, cerchiamo la probabilità di avere 3 successi
e due fallimenti su 5 prove. Se utilizzassimo la semplice regola del
prodotto, otterremmo le probabilità di avere, in ordine, 3 successi
seguiti da 2 fallimenti. Utilizzando la formula delle probabilità
binomiali di sopra, otteniamo la probabilità di avere una qualsiasi
delle permutazioni (il numero delle quali è pari a
$\frac{n!}{(n - x)!*x!}$) che contengono almeno 3 successi e 2
fallimenti.

Possiamo riscrivere le formule viste sopra per una distribuzione
generica, semplificandole conoscendo le definizioni dei simboli visti
per le distribuzioni binomiali:

-   $\mu = \sum_{}^{}\left\lbrack x*P(x) \right\rbrack$
    $\rightarrow \mu = np$

-   $\sigma^{2} = \sum\left\lbrack x^{2}*P(x) \right\rbrack - \mu^{2}$
    $\rightarrow \ \sigma^{2} = npq$

-   $\sigma = \sqrt{\sum\left\lbrack x^{2}*P(x) \right\rbrack - \mu^{2}}$
    $\rightarrow \sigma = \sqrt{npq}$

La formula per la media è intuitiva, mentre quelle per la SD e la
varianza non lo sono altrettanto. Omettiamo i calcoli per arrivarci.

## Distribuzione di Poisson -- Eventi rari

La distribuzione di Poisson è una distribuzione di probabilità discreta
che è impiegata per descrivere la probabilità che un evento si verifichi
in un certo intervallo specifico, cioè un tempo, un'area, una
distanza... specifica. La probabilità che un evento $X$ avvenga$\ x$
volte in un intervallo è definita come:

$$P(x) = \frac{\mu^{x} - e^{- \mu}}{x!}\ $$

Dove $e$ è il numero di Nepero, circa 2.71828 e μ è la media. La
distribuzione di Poisson ha σ pari a $\sqrt{\mu}$.

Una variabile, per avere una distribuzione di Poisson, deve avere i
seguenti requisiti:

-   $x$ deve indicare il numero di volte che l'evento è soddisfatto in
    un certo intervallo.

-   Gli eventi devono verificarsi in maniera indipendente l'uno
    dall'altro.

-   Gli eventi devono verificarsi in modo casuale.

Dato che la distribuzione di Poisson può essere complessa da
comprendere, utilizziamo un esempio esplicativo:

Nella Seconda guerra mondiale, la zona a sud di Londra è stata divisa in
576 regioni, ognuna di 0.25 Km quadrati. In questa zona, sono cadute un
totale di 535 bombe. In questo caso, abbiamo tutti i requisiti per una
distribuzione di Poisson:

-   Abbiamo un numero $x$ per l'evento $X$ = bombe cadute.

-   Ogni bomba è caduta indipendentemente da un'altra.

-   Le bombe sono state sganciate in maniera pressoché casuale.

Possiamo calcolare μ:

$$\mu = \frac{numero\ di\ esplosioni}{numero\ di\ regioni} = \frac{535}{576} = 0.929$$

Cerchiamo, ad esempio, la probabilità che siano cadute esattamente due
bombe ($x = 2$) in una regione qualsiasi:

$$P(x = 2) = \frac{\mu^{x} - e^{- \mu}}{x!} = \frac{{0.929}^{2}*{2.711828}^{- 0.929}}{2!} = 0.170$$

Abbiamo una probabilità del 17% che, in una qualsiasi regione, cadano
esattamente due bombe. Possiamo anche calcolare quante regioni (in
teoria) siano bombardate due volte: $0.170*576 = 97.9$. Il numero reale
è 93.

## Distribuzione normale -- Campana di Gauss

Se una variabile aleatoria continua ha una distribuzione che presenta un
grafico simmetrico, con una forma riconducibile ad una campana e può
essere descritta dalla formula:

$$N(x) = y = \frac{e^{- \frac{1}{2}\left( \frac{x - \mu}{\sigma} \right)^{2}}}{\sigma\sqrt{2\pi}\ }\ \text{ove}\ \mu\ \text{è\ la\ media\ e}\ \sigma\ \text{è\ la\ SD}\ $$

Essa è detta avere una **distribuzione normale**, o semplicemente
normale. Di solito, questa distribuzione prende il nome di $N(x)$.

Una **distribuzione normale standard** è una distribuzione normale con
$\mu = 0\ \text{e}\ \sigma = 1$. La distribuzione normale standard è
anche chiamata $Z(z)$.

Dato che la funzione per la normale è definita solo da σ e μ, possiamo
disegnarle molto facilmente dopo un'analisi preliminare dei dati. Come
abbiamo già detto prima, c'è una correlazione diretta tra area a
probabilità. Se una variabile è descrivibile da una normale particolare,
possiamo calcolare la probabilità$\ P\lbrack a \leq x \leq b\rbrack$
utilizzando la formula incontrata prima per le variabili continue:

$$N(a \leq x \leq b) = \int_{a}^{b}{f_{N}(X)}$$

La funzione che descrive la normale è però non elementarmente
integrabile, cioè non possiamo calcolarne in maniera esatta la
primitiva. Però, **I valori di probabilità per tutti i casi del tipo**
$\mathbf{Z}\left( \mathbf{z < x} \right)$, **sono stati pre-calcolati e
tabulati nel caso della normale standard.**\
Possiamo calcolare anche i casi $Z(z > x)$ semplicemente con
$1 - Z(x < z)$.

Per calcolare la probabilità, quindi, che una variabile aleatoria che
segue una distribuzione normale standard cada tra i valori $z_{1} = a$
ed $z_{2} = b$ dove $a < b$, cioè $Z(a < z < b)$ possiamo utilizzare le
definizioni viste prima:

$$Z(a \leq z \leq b) = Z(x < b) - Z(x < a)$$

In pratica, però, una serie di dati può non seguire la normale standard,
ma una normale con μ e σ diversi. Come proseguiamo per calcolare le
probabilità in questo caso, dato che la funzione non è integrabile?
Possiamo riportare i valori di $x$ della normale non standard a valori
di $z$ della normale standard in modo tale che
$P(a \leq x \leq b) = P(a \leq z \leq b)$ grazie alla formula seguente:

$$z = \frac{x - \mu}{\sigma}$$

E possiamo "tornare indietro" (ad esempio, nel caso partiamo da una
probabilità e vogliamo trovare il valore di $x$ corrispondente) dalla
formula di conversione semplicemente facendo $x = (z*\sigma) + \mu$.

## Distribuzioni campionarie di una statistica

Un centro di analisi è rimasto aperto per cinque giorni prima di
chiudere a causa del personale. In questi cinque giorni, sono stati
visitati, in ordine per ogni giorno, 3, 2, 5, 4 e 6 pazienti. Dato che
conosciamo l'intera **popolazione** "pazienti del centro", possiamo
calcolare μ e σ esattamente:

$$\mu = \ \frac{n\ tot.\ pazienti}{giorni} = \frac{20}{5} = 4\ \ \text{e}\ \ \sigma = \sqrt{\frac{\sum_{}^{}(x - \mu)^{2}}{n - 1}} = 1.58$$

Di solito, però, non conosciamo ogni valore della popolazione, dato che
trattiamo popolazioni estremamente grandi. In questi casi, prendiamo in
considerazione solo un piccolo campione della popolazione, e, basandosi
sulle caratteristiche di questo campione, cerchiamo di stimare alcune
caratteristiche della popolazione.

Ad esempio, possiamo prendere dalla "popolazione di giorni" vista prima
solo alcuni giorni, ad esempio 3, e calcolare la media di ciascuno. Dato
che parliamo di campioni, dobbiamo parlare di *media campionaria*.
Tabuliamo alcuni campioni (estratti con rimpiazzo), tutti scegliendo una
taglia campionaria pari a 3, e calcoliamo alcuni parametri:

![](media/image2.png){width="2.963888888888889in"
height="2.814583333333333in"}Calcolando la media di ciascun campione,
possiamo notare che (ignorando la duplicazione dell'ultimo risultato,
nata dal fatto che la popolazione è molto piccola) ogni media
campionaria è diversa dalle altre. In generale, possiamo considerare
ogni media campionaria diversa da tutte le altre medie di ogni altro
campione.

Se calcolassimo tutte le media campionarie per ogni permutazione della
popolazione, potremmo sapere ogni possibile valore che $\overline{x}$
può prendere. Quindi, la probabilità che un campione casuale abbia una
particolare media, è 1 sul numero di permutazioni. **Ogni media
campionaria ha quindi la stessa probabilità di essere estratta.**

Immaginiamo ora di estrarre un numero di campioni elevato, tutti di
taglia $n$, da una popolazione di grandezza $N$, per cui $N \gg n$. In
questo caso, la media campionaria di ogni campione (che sarà estratto
senza reimmissione, ma questo non ci interessa dato che $n < N*0.05$)
può coincidere in due campioni diversi. Ora immaginiamo di tabulare in
una tabella di frequenze, divise in classi appropriate, tutte queste
medie trovate. Possiamo calcolare la probabilità, utilizzando il metodo
della frequenza relativa, che, estraendo un nuovo campione, la sua media
cada in ognuna delle classi.\
Teniamo a mente questo concetto probabilistico, che utilizzeremo tra
poco.

Dato che parliamo di probabilità, possiamo disegnare una **distribuzione
campionaria della media**: essa è la distribuzione di probabilità per
tutte le medie campionarie (o le classi di medie campionarie, come è più
comune). Possiamo inoltre definire la **variabilità campionaria** di una
statistica è la variazione di questa statistica a causa della casualità
della variabile presa in questione.

Possiamo inoltre notare che la media delle medie campionarie è molto
simile alla media della popolazione. Se conoscessimo tutte le possibili
medie campionarie, e calcolassimo la media di queste, essa centrerebbe
perfettamente la media della popolazione. In generale, possiamo dire che
**la media di tutte le possibili medie campionare data una taglia è
uguale alla media della popolazione**, e si deduce che **la media
campionaria data una taglia diventa via via più vicina al valore reale
man mano che aumentano il numero di campioni**.

## Proporzioni -Distribuzione campionaria di una proporzione

Prendiamo in considerazione un altro esempio. In un'aula di cento
universitari ($N = 100$), solo tredici sono femmine. Possiamo calcolare
la **proporzione** di donne nella classe con
$F = \ \frac{13}{100} = 0.13$. Immaginando di non conoscere la
popolazione, estraiamo a sorte, con rimpiazzo (dato che la taglia
campionaria è \> 5% della popolazione), cento campioni con taglia
$n = 10$ e calcoliamo la proporzione di donne sul totale del campione
per ognuno dei campioni.

Le frequenze sono riportate in tabella:

![](media/image3.png){width="2.7008081802274715in"
height="2.208092738407699in"}Se permutassimo tutti i possibili campioni
da 10 persone (1.73 $*10^{13}$ possibili campioni) e facessimo la media
delle proporzioni di donne otterremmo 0.13. In cento campioni, otteniamo
una media delle proporzioni di 0.12, che è abbastanza vicina al valore
reale.

In generale, **le proporzioni campionarie tendono a centrare il valore
delle proporzioni di popolazione, diventando via via più precise
maggiore è il numero di campioni raccolti.**

Come si potrebbe notare dalla tabella a fianco, le proporzioni
campionarie hanno una classe di frequenza massima (0.1), e la
proporzione scende sempre di più allontanandoci da questa classe.

![](media/image4.png){width="3.3465277777777778in"
height="1.7965277777777777in"}Se ripetiamo lo stesso esperimento, ma
prendendo 10\'000 campioni con $n = 50$, otterremmo un grafico
generalmente come quello a destra. Possiamo notare che la distribuzione
delle probabilità sembra seguire molto bene una normale.

Possiamo dire che, in generale, **le distribuzioni delle proporzioni
campionarie, sotto alcune condizioni, sono approssimabili da una
distribuzione normale.**

Come abbiamo visto, alcune statistiche riescono a centrare bene i
parametri della popolazione, mentre altri no. Le statistiche che
centrano i parametri corrispondenti sono detti **stimatori non
distorti**, mentre quelli che non li centrano sono detti **stimatori
distorti**. Per riassumere:

-   **Stimatori non distorti**: media, varianza, proporzione.

-   **Stimatori distorti**: mediana, range, deviazione standard.

## Il teorema del Limite Centrale

Ricordando la definizione di *variabile aleatoria*, di *distribuzione
delle probabilità* e *distribuzione della media campionaria* possiamo
introdurre il teorema del limite centrale.

Il **teorema del limite centrale** afferma che, se la taglia del
campione è abbastanza grande, la distribuzione delle medie campionarie
può essere approssimata ad una **distribuzione normale**, anche se la
popolazione non ha questa distribuzione.

Questo teorema ci permette di descrivere qualsiasi popolazione,
ignorando la distribuzione della popolazione stessa, con una
distribuzione normale se possiamo estrarre campioni sufficientemente
grandi. Vediamo il teorema in dettaglio:

-   **Ipotesi**

    -   La variabile aleatoria $X$ ha una distribuzione (anche non
        normale), con media $\mu$ e deviazione standard $\sigma$.

    -   Selezioniamo dalla popolazione campioni tutti di taglia $n$ in
        modo casuale semplice.

-   **Conclusioni**

    -   Se $n$ cresce, la distribuzione delle medie campionarie
        $\overline{x}$ si avvicina alla distribuzione normale.

    -   La media della distribuzione delle medie campionarie (la media
        delle medie) è la media della popolazione $\mu$.

    -   La deviazione standard della distribuzione delle medie
        campionarie è pari a $\frac{\sigma}{\sqrt{n}}$.

Per parlare di media e SD della distribuzione delle medie campionarie
occorrono nuovi simboli:

-   Media delle medie campionarie: $\mu_{\overline{x}} = \mu$

-   SD delle medie campionarie:
    $\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}$

    -   $\sigma_{\overline{x}}$ è anche chiamato **errore standard della
        media**.

Il teorema del limite centrale è ben visibile negli esempi fatti prima
al riguardo delle medie campionarie. Anche se le possibili medie
campionarie hanno tutte la stessa probabilità di essere estratte
($\frac{1}{permutazioni}$), la distribuzione delle medie campionarie
assomiglia ad una normale proprio per il fatto che tutte le medie hanno
la stessa probabilità di estrazione.

Per utilizzare la distribuzione normale delle medie, però, probabilmente
dovrà essere trasformata in una normale standard. Dobbiamo ricordare di
utilizzare sia media che SD della distribuzione delle medie,
sostituendola nella formula vista prima:

$$z = \frac{\overline{x} - \mu_{\overline{x}}}{\sigma_{\overline{x}}} = \frac{\overline{x} - \mu}{\frac{\sigma}{\sqrt{n}}} = \frac{\left( \overline{x} - \mu \right)*\sqrt{n}}{\sigma}$$

Questa formula è applicabile se conosciamo a priori $\sigma$ della
popolazione. Se non conosciamo $\sigma$, dobbiamo stimarla partendo
dalle medie campionarie. Come abbiamo visto, la deviazione standard
campionaria è uno stimatore distorto di $\sigma$, allora dobbiamo
necessariamente calcolare la deviazione standard partendo dalla varianza
(che non è distorto). Se $m$ è il numero di campioni,
$\mu_{\overline{x}}$ è la media di tutte le medie campionarie e
$\overline{x}$ è ogni singola media campionaria, allora:

$$\sigma_{\overline{x}} = \sqrt{Var\left( \overline{X} \right)} = \sqrt{\frac{1}{m}\sum_{}^{}\left( \overline{x}\  - \mu_{\overline{x}} \right)^{2}}$$

## Accertare la normalità di una distribuzione

Possiamo controllare che una distribuzione è normale seguendo il
processo generale:

1.  **Istogramma**. Se la distribuzione non ha una forma a campana,
    rifiutiamo la normalità.

2.  **Outlier**. Rifiutiamo la normalità se c'è più di un *outlier*.

3.  **Grafico dei quantili normali**. Se i punti 1. E 2. sono
    soddisfatti, costruiamo il grafico dei quantili normali. In questo
    grafico, l'asse x mostra i valori originari della distribuzione, e
    l'asse y mostra i corrispondenti valori di $z$ dopo aver
    standardizzato $x$. Se i punti non giacciono su una linea retta, o
    se seguono un disegno sistematico che non è una linea retta,
    rifiutiamo la normalità

4.  Se tutti gli altri punti sono soddisfatti, allora non possiamo
    rifiutare la normalità della distribuzione.

# Capitolo 4 -- Stime con un campione

Ora iniziamo a vedere come usare le statistiche di un campione per
inferire sui parametri di popolazione. Questo è il vero nucleo della
statistica inferenziale, e con questi metodi possiamo sia stimare il
valore di un parametro partendo da una statistica, sia tastare alcune
ipotesi circa la popolazione partendo da dei campioni.

## Stima delle proporzioni in una popolazione

Ora stimeremo la proporzione di una popolazione partendo da una
proporzione campionaria. Per poter far questo, dobbiamo utilizzare dei
dati con alcune caratteristiche:

-   Il campione deve essere casuale semplice;

-   La distribuzione deve essere di tipo binomiale: ci sono un numero
    finito di prove, ogni prova non influenza il risultato di un\'altra
    prova, ci sono solo due possibili esiti (successo ed insuccesso) e
    la probabilità di successo rimane invariata tra le diverse prove.

-   Prendiamo in considerazione solo le proporzioni per cui la
    distribuzione campionaria è assimilabile ad una normale.
    Considerando un evento binomiale, se $n$ è il numero di prove e $p$
    è la probabilità di successo, e $np \geq 5\ \text{e}\ nq \geq 5$, la
    distribuzione delle proporzioni è normale. Dato che $p$ (e quindi
    anche $q$) sono incognite, dovremo utilizzare le proporzioni
    campionarie per stimarne i loro valori e accettarsi che queste
    condizioni sono soddisfatte.

Notiamo alcuni simboli utilizzati più avanti:

-   $p$ è la proporzione di successi ($\frac{successi}{totale\ prove}$)
    della popolazione.

-   $\widehat{p}$ è la proporzione campionaria di $x$ successi sul
    campione di prove di taglia $n$. $\widehat{p} = \frac{x}{n}$

-   $\widehat{q} = 1 - \widehat{p}$, cioè la proporzione di fallimenti
    su un campione di taglia $n$.

Nota: possiamo considerare proporzioni anche probabilità e percentuali
oltre che ad una generica proporzione $p$, ma bisogna ricordarsi di
trasformare da un valore percentuale ad un valore semplice queste due
misure. Ad esempio, una probabilità del 22.3% è pari ad una probabilità
di 0.223.

Ad esempio, se il 30% dei baccelli in un campione di 530 piante sono
gialli, allora $\widehat{p} = 0.30$ e $\widehat{q} = 0.70$.

Se vogliamo stimare la proporzione di popolazione con un singolo valore,
la migliore stima sarà $\widehat{p}$. In questo caso, $\widehat{p}$ è
**stimatore puntuale** del parametro proporzione. In generale, uno
stimatore puntuale è un singolo valore (un punto) usato per stimare un
parametro di popolazione. Utilizziamo $\widehat{p}$ perché è uno
stimatore non distorto, come abbiamo visto prima. Inoltre, la
proporzione campionaria è lo stimatore più robusto tra quelli che
possiamo utilizzare, cioè la deviazione standard di $\widehat{p}$ dal
valore di popolazione, rispetto ad altri stimatori di $p$, è minore.

## Gli intervalli di confidenza

Abbiamo detto che $\widehat{p}$ è il miglior stimatore di $p$, ma
abbiamo alcuna indicazione di *quanto* sia buona questa stima. Dato che
la stima puntuale in sé non rivela la propria qualità, si sono messi a
punto metodi per stimare il valore di popolazione non più con un punto,
ma utilizzando un **range** di valori per poter avere una certa
confidenza che il valore vero di $p$ cada in questo intervallo.

Un **intervallo di confidenza** (IC) è un range di valori usati per
stimare il valore vero del parametro di popolazione.

Un intervallo di confidenza è calcolato partendo dal **livello di
confidenza** (o **grado di fiducia**, o **coefficiente di confidenza**)
scelto dall'operatore (ad esempio, 95%). Questo valore ci dà la
percentuale di successo che, dopo aver calcolato l'intervallo di
confidenza, esso contenga effettivamente $p$. Quindi, se scegliamo 0.95,
su un certo numeri di intervalli di confidenza calcolati per prove
diverse, il 95% di questi conterranno $p$. Bisogna sottolineare che il
livello di confidenza **non è una probabilità**: quando calcoliamo
l'intervallo per un certo set di dati, otterremo sempre lo stesso range.
È quindi errato parlare di probabilità di successo, ma solo di
confidenza di successo.

Di solito, il livello di confidenza è indicato come $1 - \alpha$, dove
$\alpha$ è il complementare del livello di confidenza desiderato, ad
esempio 0.05 per 0.95 di confidenza.

Il livello di confidenza determina pesantemente la forma
dell'intervallo: per avere un 100% di confidenza che $p$ cada
nell'intervallo, dovremmo prendere, in teoria, un intervallo di range
infinito. Quindi, man mano che il grado di confidenza sale, l'intervallo
cresce di range. Il contrario vale per un grado di confidenza
decrescente.

La distribuzione delle proporzioni è una normale. Possiamo quindi
trovare un valore di $z$ che divide le proporzioni che hanno più
probabilità di essere esatte (verso il centro della distribuzione), da
quelle che ne hanno di meno. Definiamo ora questo valore, considerazione
per considerazione, chiamato **valore critico**:

-   Sotto alcune condizioni, la distribuzione campionaria delle
    proporzioni è una normale.

-   Le proporzioni che hanno probabilità più piccola di $\alpha$ sono
    nelle "code" destra e sinistra della distribuzione normale. L'area
    delle code (entrambe sommate assieme) è quindi pari ad $\alpha$.
    L'area di una singola coda sarà $\frac{\alpha}{2}$.

-   C'è una probabilità pari a $1 - \alpha$ che le proporzioni cadano
    nella parte più centrale della distribuzione.

-   Il valore di $z$ che separa la coda destra (quindi $z > 0$, e l'area
    a destra partendo da $z$ è pari a $\frac{\alpha}{2}$) è indicato
    come $z_{\frac{\alpha}{2}}$. $z_{\frac{\alpha}{2}}$ è chiamato
    **valore critico**.

Per riassumere: Il **valore critico** $z_{\frac{\alpha}{2}}$ è il valore
positivo di $z$ in corrispondenza della linea verticale che separa
un'area pari ad $\frac{\alpha}{2}$ nella coda destra della distribuzione
normale standard.

![](media/image5.png){width="2.33125in"
height="0.7430555555555556in"}Per trovare il valore critico, iniziamo a
definire $\alpha$. Se vogliamo un livello di confidenza del 95%, allora
$\alpha = 0.05$, quindi l'area sottesa dalla distribuzione dopo il
valore critico sarà $\frac{\alpha}{2}$, cioè $0.025$. La tabella che
relaziona $z$ alle corrispondenti aree dà solo le aree da $z$ verso
sinistra, quindi utilizziamo l'area di $1 - 0.025 = 0.975$, che trova il
valore di $z$, cioè il nostro valore critico
$z_{\frac{\alpha}{2}} = 1.96$.

Altri valori critici, trovati nello stesso modo, sono ripotati nella
tabella a fianco. Il livello di confidenza più usato è 95%, ma possiamo
anche utilizzare 90% o 99%.

Ora definiamo un altro valore che è importante per calcolare gli
intervalli di confidenza, il **margine di errore**. Il margine di
errore, denominato $\mathbf{E}$, è la differenza massima tra la
proporzione $\widehat{p}$ del campione e il vero valore $p$ della
popolazione. Il margine di errore è calcolato moltiplicando la
deviazione standard campionaria per il valore critico:

$$E = z_{\frac{\alpha}{2}}\sqrt{\frac{\widehat{p}\widehat{q}}{n}}$$

**Quindi, dato un** $\mathbf{\alpha}$**, la proporzione campionaria sarà
errata di una quantità non superiore ad** $\mathbf{E}$ **con una
probabilità di** $\mathbf{1 - \alpha}$**, e errata di una quantità
superiore ad** $\mathbf{E}$ **con una probabilità**
$\mathbf{\alpha}$**:** Questo si prende come viene?

$$\widehat{p} - E < p < \widehat{p} + E$$

Questo che abbiamo appena trovato è proprio l'**intervallo di
confidenza** **per la distribuzione binomiale**. Spesso l'IC è segnato
come $\widehat{p} \pm E$.

Ricordiamo che l'intervallo di confidenza non è una probabilità: $p$ è
una costante, quindi non ha senso dire "*abbiamo una probabilità del 95%
che* $p$ *cada tra a e b*", dato che il valore di $p$ non cambia, e non
c'è nessuna probabilità coinvolta.

Quanto grande deve essere $n$ per ottenere un buon valore di $E$?
Posiamo calcolare la taglia campionaria ideale per un certo esperimento
in due modi, partendo sempre dalla formula inversa di $E$. Se conosciamo
già una stima di $\widehat{p}$ (magari da studi più vecchi), possiamo
semplicemente applicare la formula del margine di errore in modo
inverso:

$$n = \frac{\left( z_{\frac{\alpha}{2}} \right)^{2}\widehat{p}\widehat{q}}{E^{2}}$$

Se non conosciamo una stima della proporzione campionaria, allora
sostituiamo $\widehat{p}\widehat{q}$ con il massimo valore che quella
moltiplicazione può avere (se $\widehat{p}$ e $\widehat{q} = 0.5$), cioè
0.25:

$$n = \frac{\left( z_{\frac{\alpha}{2}} \right)^{2}*0.25}{E^{2}}$$

Ricordare di arrotondare sempre per eccesso, così da avere un $n$
abbastanza grande. Notare che $n$ non dipende da $N$, cioè dalla taglia
della popolazione.

## Stima della media di una popolazione

Per stimare la media occorre utilizzare $\sigma$,la deviazione standard.
La SD della popolazione potrebbe essere conosciuta (magari da altri
studi) o essere incognita, e il metodo per calcolare la stima della
media varia nei due casi. Il caso che la deviazione standard è
conosciuta mentre la media di popolazione non lo è è raro, ma è utile
considerarli entrambi per capire i metodi statistici al di sotto delle
considearazioni:

### La deviazione standard è nota

Come prima, abbiamo dei requisiti:

1.  Il campione è casuale semplice.

2.  $\sigma$ è noto.

3.  Sono soddisfatti almeno uno di questi due requisiti di normalità per
    la distribuzione delle medie campionarie:

    a.  La popolazione ha una distribuzione normale.

    b.  $n > 30$. Questo rende, qualsiasi sia la distribuzione della
        popolazione, la distribuzione delle medie campionare una
        normale, per il **teorema del limite centrale**. Il valore di 30
        basta dato che questo metodo è considerato **robusto**, cioè non
        è influenzato pesantemente dalla non perfetta normalità della
        distribuzione. Comunque, più $n$ cresce, migliori sono le stime.

Per iniziare, ricordiamo che la media campionaria $\overline{x}$ è la
migliore stima del parametro $\mu$ di popolazione. Questo è vero
sperimentalmente: si è visto che la distribuzione delle medie
campionarie è più consistente (cioè con SD minore) rispetto a altre
statistiche come media o moda, e $\overline{x}$ tende a centrare μ.

Anche qui calcoliamo un intervallo di confidenza, utilizzando la
definizione di SD della media campionaria vista prima, sostituendola
nella formula di $E$:

$$E = z_{\frac{\alpha}{2}}*\frac{\sigma}{\sqrt{n}}$$

Quindi il nostro intervallo di confidenza sarà $\overline{x} \pm E$, o
$\overline{x} - E < \mu < \overline{x} + E$.

Anche qui, possiamo stimare la taglia del campione $n$ per ottenere un
intervallo di confidenza accettabile. Possiamo di nuovo proseguire come
prima, facendo l'inverso della formula di $E$:

$$n = \left\lbrack \frac{z_{\frac{\alpha}{2}}*\sigma}{E} \right\rbrack^{2}$$

Di nuovo, non conoscendo esattamente σ, potremmo cercare di stimarla da
studi vecchi oppure da studi correlati: Se sappiamo che σ dei quozienti
intellettivi della popolazione "italiani" è 15, allora, se prendiamo in
considerazione come popolazione un sottogruppo di "italiani" possiamo
provare ad utilizzare 15 come σ della nuova popolazione.

### La deviazione standard non è nota

Quando σ non è nota, abbiamo comunque il requisito di campionamento
casuale semplice e che le medie campionarie seguano una distribuzione
normale (quindi che la popolazione sia normale o che $n > 30$), anche se
il requisito di normalità è sempre non troppo severo per la robustezza
del metodo.

Se σ è incognita, possiamo usare una distribuzione simile alla normale,
chiamata ***distribuzione t di Student*** (sviluppata da William Gosset
(1876-1987). Perché utilizziamo questa distribuzione? Non conoscendo σ,
la stimiamo con la statistica s, la deviazione standard del campione.
Questo però aggiunge una variabile di inaffidabilità: oltra a dover
stimare la media con $\overline{x}$, dobbiamo anche stimare la SD con
$s$. Questa addizionale variazione è compensata dal range più ampio che
la distribuzione di Student porta ad avere, dati i valori critici
diversi $z_{\frac{\alpha}{2}}$ calcolati, che in questo caso prendono il
nome di $t_{\frac{\alpha}{2}}$.

Se la distribuzione della popolazione è essenzialmente normale, allora
la distribuzione di $t$ in modo che:

$$t = \frac{\overline{x} - \mu}{\left( \frac{s}{\sqrt{n}} \right)} = \frac{\left( \overline{x} - \mu \right)\sqrt{n}}{s}$$

È essenzialmente una distribuzione **t di Student,** o semplicemente
**distribuzione t** per tutti i campioni di taglia $n$.

I valori di $t_{\frac{\alpha}{2}}$ sono tabulati, come per la normale
standard. Esistono varie versioni della distribuzione t, in base ai
**gradi di libertà** del campione. Questa nuova variabile è di nuovo per
tenere conto del maggiore errore che l'introduzione della stima di
$\sigma$ porta nell'intervallo: minore è $n$, maggiore il valore di s è
incerto, quindi più ampio è l'intervallo che bisogna calcolare. I gradi
di libertà sono, appunto, il numero di possibili valori che possono
variare dopo aver imposto delle restrizioni. La distribuzione t è
identica ad una normale standard se i gradi di libertà sono infiniti,
cioè il campione ha taglia infinita (o molto, molto grande).

Ad esempio, se 10 studenti hanno preso dei voti con media pari a 80, la
sommatoria di tutti i voti deve essere 800. Se i primi 9 voti sono
aleatori, cioè possono prendere (con dovuti limiti) qualsiasi valore,
l'ultimo no: deve essere per forza pari a
$800 - \sum_{}^{}{altri\ voti}$. Quindi, per quello che interessa a noi,
il valore dei gradi di libertà è pari a $n - 1$.

Possiamo ora definire l'intervallo di confidenza per la media
campionaria $\overline{x}$, dato un $\alpha$, come:

$$\overline{x} - E < \mu < \overline{x} + E\ \text{dove}$$

$E = t_{\frac{\alpha}{2}}*\frac{s}{\sqrt{n}}$

con $t_{\frac{\alpha}{2}}$ avente $n - 1$ gradi di libertà.

Notiamo qui alcune caratteristiche della distribuzione t di Student:

-   Essa cambia per taglie campionarie diverse (dato che cambia il
    valore di gradi di libertà);

-   Essa ha comunque una forma a campana, ma con una maggiore
    variabilità (la curtosi cambia);

-   Essa ha una media $t = 0$, come la normale standard;

-   La deviazione standard cambia in base alla taglia campionaria, ma è
    sempre maggiore di 1 (con $n < \infty$);

-   All'aumentare della taglia campionaria, la distribuzione t di
    Student diventa sempre più simile ad una normale standard.

-   L'area sottesa dalla funzione è sempre 1.

Quando usiamo la normale standard, e quando utilizziamo la t di Student?
La tabella qui sotto può chiarirci le idee:

![C:\\Users\\hedma\\Downloads\\Untitled
Diagram.png](media/image6.png){width="4.16875in" height="3.075in"}

## Stima della varianza di una popolazione

Parallelamente a cosa abbiamo fatto per le altre statistiche, anche per
la varianza sono necessari alcuni requisiti:

-   I campioni sono casuali semplici;

-   **La *[popolazione]{.underline}* è distribuita normalmente, anche
    se** $\mathbf{n}$ **è grande**. Questo requisito è tassativo, e la
    normalità deve essere appurata come descritto prima, con istogrammi
    e grafici dei quantili. Questo metodo non è robusto, e la mancata
    normalità della popolazione porta a grandi errori.

Anche qui dobbiamo utilizzare una nuova distribuzione, come per la media
abbiamo usato la t di Student: la distribuzione *chi-quadro*,
$\chi^{2}$.

![](media/image7.png){width="2.694430227471566in"
height="2.0231222659667543in"}Data una popolazione con distribuzione
normale, dopo aver estratto con il metodo casuale semplice una serie di
campioni indipendenti di taglia $n$, e calcoliamo la varianza
campionaria $s^{2}$ per ogni campione, allora la statistica campionaria:

$$\chi^{2} = \frac{(n - 1)s^{2}}{\sigma^{2}}$$

Dove $\sigma^{2}$ è la varianza di popolazione, ha una distribuzione
chiamata **distribuzione chi-quadro**.

Anche la distribuzione chi quadro è determinata di gradi di libertà del
campione, determinati come $n - 1$. La distribuzione è mostrata a
fianco, con $k = n - 1$. Descriviamo delle caratteristiche della
funzione:

-   Non è simmetrica. Essa diventa sempre più simmetrica all'aumentare
    di $k$.

-   I valori di una distribuzione chi quadro non possono essere negativi
    (tutto nella formula è necessariamente positivo)

-   La distribuzione cambia per ogni valore di $k$. Se $k = \ \infty$,
    la funzione è identica ad una normale.

-   L'area totale sottesa dalla funzione è sempre 1.

Dato che la distribuzione $\chi^{2}$ non è simmetrica, la notazione
degli intervalli di confidenza $s^{2} \pm E$ non è corretta, dobbiamo
infatti fare due calcoli di $E$ per il limite sinistro e destro,
utilizzando i valori di $\chi_{L}^{2}$ e $\chi_{R}^{2}$ rispettivamente.

La varianza campionaria è uno stimatore non distorto della varianza di
popolazione, e possiamo calcolarne l'intervallo di confidenza come:

$$\frac{(n - 1)s^{2}}{\chi_{R}^{2}} < \sigma^{2} < \frac{(n - 1)s^{2}}{\chi_{L}^{2}}$$

Invece, la deviazione standard non è un buon stimatore, dato che è
distorto, ma è comunque utilizzata. Possiamo calcolarne l'intervallo di
confidenza come le radici degli estremi dell'intervallo per la varianza:

$$\sqrt{\frac{(n - 1)s^{2}}{\chi_{R}^{2}}} < \sigma^{2} < \sqrt{\frac{(n - 1)s^{2}}{\chi_{L}^{2}}}$$

I calcoli per trovare la taglia campionaria $n$ non sono così semplici
come gli altri due esempi. Di solito si utilizzano calcolatori come R o
STATDISK. Comunque, a scopo di esempio, la taglia campionaria per avere
un intervallo di confidenza del 95% è 3148, mentre per averlo del 99% è
77207. Da questi numeri capiamo quanto è inefficace il metodo per
stimare la varianza e la deviazione standard.

# Capitolo 5 -- Verifica di un'ipotesi

Spesso ci chiediamo quando una nostra ipotesi è confermata o meno da un
esperimento. Ad esempio, gli esperimenti di Mendel portano ad avere un
26.7% di baccelli gialli, quando l'ipotesi mendeliana ne predice un 25%.
Come possiamo affermare che l'ipotesi di Mendel è esatta? Come possiamo
determinare se invece è falsa?

Definiamo alcuni termini:

-   In statistica, un'**ipotesi** è una dichiarazione o affermazione
    riguardante una proprietà di una popolazione.

-   Un **test di ipotesi** o **test di significatività** è una procedura
    standard per verificare un'ipotesi.

Questo capitolo fa uso pesantemente della **legge degli eventi rari**
vista nel capitolo di probabilità: Se sotto una determinata ipotesi, la
probabilità di un particolare evento osservato è eccezionalmente bassa,
concludiamo che l'ipotesi è verosimilmente sbagliata.

Prendiamo in considerazione questo esempio: Una casa farmaceutica
produce un prodotto che, a quanto affermato, aumenta la probabilità che
venga concepita una femmina. Sappiamo che la probabilità normale $p$ che
venga concepita una femmina è $p = 0.50$. In un esperimento, cento
coppie che hanno utilizzato il prodotto hanno avuto un figlio ciascuna,
e dei 100 nascituri 52 erano femmine. Notiamo che avere *x successi in n
prove è un numero insolitamente alto di successi se*
$P\left( x\ o\ piu^{'} \right)$ *è molto piccolo*, ad esempio più
piccolo di 0.05. **Se è poco probabile che escano numeri più grandi di**
$\mathbf{x}$***,* allora** $\mathbf{x}$ **è un numero molto grande in
quella distribuzione.** Allo stesso modo, $x$ è un numero insolitamente
piccolo se $P(x\ o\ meno)$ è piccola. Possiamo utilizzare il teorema del
limite centrale per trattare i dati come una distribuzione normale, e
calcolare la probabilità che siano nate 52 o più femmine su 100
nascituri: $P\left( 52\ o\ piu^{'} \right) = 0.3821$. Dato che la
probabilità che nasca una femmina sono del 0.5, possiamo dire che il
prodotto in realtà non funziona, dato che non abbiamo nessuna evidenza
che ci fa pensare che la differenza tra le 50/100 femmine teoriche e le
52/100 femmine ottenute non sia dovuta al semplice caso. In altre
parole, il 52% di femmine in un campione con $n = 100$ non è insolito se
la vera probabilità di avere una femmina è $p = 50\%$.

Per definire un test statistico, dobbiamo prima definire formalmente
alcuni concetti che saranno utilizzati:

-   L'ipotesi nulla, denotata con $H_{0}$, afferma che il parametro di
    popolazione è uguale ad un certo valore.\
    Ad esempio, $H_{0}:\mu = 98.3$

-   L'ipotesi alternativa, denotata con $H_{1}\ o\ H_{a}$, afferma che
    il parametro della popolazione differisce da quanto affermato
    dall'ipotesi nulla. Per questo capitolo, l'ipotesi alternativa deve
    sempre contenere $> ,\  < ,\  \neq$.

    -   Se si vuole utilizzare un test statistico per sostenere le
        proprie affermazioni, bisogna esprimere tali affermazioni come
        ipotesi nulle, e questo richiede l'uso dei simboli
        $> ,\  < ,\  \neq$. Non possiamo utilizzare un test di ipotesi
        per affermare che un parametro è uguale ad un valore.

**Statistica di test**

La statistica di test è un valore calcolato utilizzando i dati
campionari, che è usato per decidere **se rifiutare** **l'ipotesi
nulla**. Questo valore è determinato trasformando la statistica
campionaria in un **punteggio immaginando che l'ipotesi nulla sia
vera**:

Statistica di test per la **proporzione**:

$$z = \frac{\widehat{p} - p}{\sqrt{\frac{pq}{n}}}$$

Statistica di test per la **media**:

$$z = \frac{\overline{x} - \mu}{\frac{\sigma}{\sqrt{n}}}\ \text{oppure}\ t = \frac{\overline{x} - \mu}{\frac{s}{\sqrt{n}}}$$

Statistica di test per la **deviazione standard**:

$$\chi^{2} = \frac{(n - 1)s^{2}}{\sigma^{2}}$$

**Esempio esplicativo**:

Prendiamo in considerazione un test di genetica mendeliana: su 580
piante di pisello, il 26.2% ($\widehat{p} = 0.262$) risulta avere
baccelli gialli. Mendel dichiara che il valore teorico di baccelli
gialli è 25%. Con una statistica di test cerchiamo di capire se i dati
ottenuti si discostano molto dal valore teorico dichiarato da Mendel:

L'ipotesi nulla è $H_{0}:p = 0.25$, mentre l'ipotesi alternativa è
$H_{1}:p \neq 0.25$. Dato che lavoriamo sotto l'ipotesi che $H_{0}$ sia
vera, allora che $p = 0.25$, otteniamo la statistica di test
(utilizzando la formula qui sopra per le proporzioni):

$$z = \frac{\widehat{p} - p}{\sqrt{\frac{pq}{n}}} = \frac{0.262 - 0.25}{\sqrt{\frac{0.25*0.75}{580}}} = 0.67$$

Dal capitolo precedente, possiamo dire che il valore di $z = 0.67$ non è
molto grande (sarebbe grande se fosse maggiore di 2 o minore di 2, per
cui i dati campionari sono più distanti dalla media di 2 deviazioni
standard): possiamo dire che in questo caso 26.2% non è
*significativamente* diverso da 25%, quindi non possiamo dire che
l'ipotesi $H_{0}$ è rifiutata.

-   La **regione critica**, o **regione di rifiuto**, è l'insieme di
    tutti i valori della statistica di test che ci portano a rifiutare
    l'ipotesi nulla. Questi sono arbitrari, ma di solito sono le zone di
    "coda" della distribuzione normale.

-   Il **livello di significatività** (α) è la probabilità che la
    statistica di test cada nella regione critica anche quando l'ipotesi
    nulla è vera; α, quindi è la probabilità di commettere un errore.
    Questa α è la stessa che abbiamo introdotto qualche capitolo fa al
    riguardo della creazione degli intervalli di confidenza, e quindi di
    solito prende il valore di 0.05, 0.01 o 0.10.

-   Un **valore critico** è qualsiasi valore che separa la regione
    critica da quella che porta al non rifiuto dell'ipotesi nulla. Ad
    esempio, per α = 0.05 in un test a due code (vedi sotto), il valore
    critico è z = ± 1.96.

Notiamo che se la nostra ipotesi $H_{1}$ è del tipo "$p \neq 12$",
allora possiamo commettere due tipi di errori: sia sovrastimare la
proporzione, e quindi cadere nella coda di destra della distribuzione,
sia sottostimare la proporzione, e quindi cadere nella coda di sinistra.
La nostra regione critica è quindi sia a sinistra che a destra. Questo
tipo di test è detto **a due code**. I valori critici sono i valori di z
che delimitano due aree, a sinistra e a destra, per cui
$area\ sx + area\ dx = \alpha = 0.05$; quindi $z = \pm 1.96$

Se la nostra ipotesi alternativa è del tipo "$p > 12$", allora non sarà
possibile sottostimare la proporzione, dato che stiamo solo considerando
solo valori più grandi di $p$. In questo caso, l'unico errore possibile
è sovrastimare la proporzione, e l'area critica è solo a destra, e la
sua area è pari a α, di solito 0.05. Questo test è chiamato **a coda
destra,** e in questo caso il valore di $z$, con $\alpha = 0.05$ è +
1.64.

Nello stesso modo, se l'ipotesi alternativa è del tipo "$p < 12$", il
test è **a coda sinistra**, e il valore di $z$ con $\alpha = 0.05$ è
-1.64.

Possiamo ricordare quale tipo di test è associato ad un'ipotesi nulla
semplicemente pensando a quali valori sono significativamente
discostanti dall'ipotesi nulla, ed osservando il segno dell'ipotesi
alternativa:
$\neq \rightarrow 2\ code; < \  \rightarrow coda\ sx; > \  \rightarrow coda\ dx$.

Il **p-value** è la probabilità che il valore della statistica di test
calcolato per la popolazione sia maggiore o uguale a quello calcolato
con i dati campionari, se l'ipotesi nulla è vera. L'ipotesi nulla è
rifiutata se il p-value è meno di α, ad esempio inferiore a 0.05. I
P-value sono calcolati in questo modo:

-   Per i test ad una coda, il p-value è il valore dell'area della
    distribuzione rispettivamente alla destra o alla sinistra della
    statistica di test per i test a coda destra e coda sinistra.

-   Per i test a due code, il p-value è il **doppio** dell'area più
    piccola che si ottiene partendo dal valore di statistica di test e
    considerando l'area destra o sinistra.

### Prendere una decisione ed arrivare ad una conclusione

I test di ipotesi portano sempre ad avere una delle due conclusioni:

-   L'ipotesi nulla è rifiutata

-   L'ipotesi nulla non è rifiutata

La nostra ipotesi può essere sia l'ipotesi nulla che l'ipotesi
alternativa, ma il risultato del test statistico è sempre lo stesso.
Abbiamo quindi più modi per decidere se rifiutare o meno l'ipotesi
nulla:

-   **Metodo tradizionale**: rifiuto $H_{0}$ se la statistica di test
    cade nella regione critica. Non rifiuto $H_{0}$ se la statistica di
    test cade fuori dalla regione critica.

-   **Metodo del p-value**: rifiuto $H_{0}$ se il valore del p-value è
    minore o uguale ad α. Non rifiuto $H_{0}$ se il p-value è maggiore
    di α.

    -   **Opzione alternativa**: Non determino α, ma calcolo solo il
        p-value e lascio la scelta al lettore di determinare se $H_{0}$
        è da rifiutare o meno.

-   **Intervalli di confidenza**: Se il valore dell'ipotesi $H_{0}$ è
    fuori dall'intervallo di confidenza per quel parametro, rifiuto
    $H_{0}$. Notare che se il test è ad una coda, la confidenza
    dell'intervallo deve essere $1 - 2\alpha$.

    -   L'uso dell'intervallo di confidenza aggiunge il possibile errore
        di stimare la SD della popolazione, pertanto non è molto
        utilizzato, e, se il metodo del p-value e quello tradizionale
        sono equivalenti tra loro, non lo sono con il metodo
        dell'intervallo di confidenza.

Se utilizziamo il metodo del p-value, è meglio determinare α prima
dell'analisi, per non essere tentati di scegliere α in base al
risultato.

Per esprimere I nostri risultati in forma più comprensibile per qualcuno
che non ha seguito un corso di Statistica potremmo dire:

-   Se l'ipotesi origine contiene un'uguaglianza (è quindi $H_{0}$):

    -   $H_{0}$ è rifiutata: "*C'è un'evidenza statistica sufficiente
        per garantire il rifiuto dell'ipotesi per cui...*"

    -   $H_{0}$ non è rifiutata: "*Non c'è un'evidenza statistica
        sufficiente per garantire il rifiuto dell'ipotesi per cui...*"

-   Se l'ipotesi originale non contiene una condizione di uguaglianza (è
    quindi $H_{1}$):

    -   $H_{0}$ è rifiutata: "*I dati campionari sostengono l'ipotesi
        per cui...*"

    -   $H_{0}$ non è rifiutata: "*Non c'è un'evidenza campionaria
        sufficiente per sostenere l'ipotesi per cui...*"

### Errori durante lo svolgimento di un test d'ipotesi

![](media/image8.jpeg){width="2.2832370953630794in"
height="1.2111154855643045in"}Durante un test, anche se tutto è
calcolato esattamente, rischiamo comunque di avere un errore. Questi
errori sono di due nature: In realtà l'ipotesi $H_{0}$ è falsa, ma non
l'abbiamo rifiutata (Errore di tipo 1, o **falso positivo**); in realtà
l'ipotesi $H_{0}$ è vera, ma l'abbiamo rifiutata (Errore di tipo 2, o
**falso negativo**).

Le probabilità di commettere questi errori sono definite come $\alpha$
per l'errore di prima specie, e $\beta$ per l'errore di seconda specie.

Il migliore dei casi sarebbe quando sia alfa che beta fossero zero, ma
questo non è possibile: dobbiamo trovare un buon compromesso tra i due
tipi di errore. α è già selezionato prima, ad esempio 0.05. Si può
dimostrare che α, β e $n$ (la taglia campionaria) sono in relazione
matematica. Di solito si fissano due di queste variabili per ottenere la
terza con un valore accettabile. Di solito si fissano α e $\beta$, per
ottenere un $n$ al di sotto di 0.2. Queste considerazioni pratiche sono
vere:

-   Per un valore di α fissato, un incremento di $n$ porta ad una
    diminuzione di β.

-   Per un valore di $n$ fissato, α e β sono tra di loro inversamente
    proporzionali: all'aumento di uno l'altro diminuisce.

-   L'incremento di $n$ porta ad una diminuzione sia di α che di β.

Dalla definizione di errore di seconda specie possiamo dire che
$1 - \beta$ è pari alla probabilità di rifiutare l'ipotesi nulla se essa
è falsa. Ci si riferisce a questa probabilità come **potenza del test**.
La probabilità β è influenzata, però, da α, $n$, e dal valore che è
considerato come alternativo nell'eseguire il test. Uno stesso test,
quindi, può avere molteplici potenze. Spesso si cerca di determinare a
priori $n$ considerando quale potenza vogliamo per il nostro test
(minimo 0.80).

Riassumiamo qui i metodi per un test di ipotesi in ciascuno dei
parametri visti:

#### Test di ipotesi per una **proporzione**

-   **Requisiti**

    -   Il campione è casuale semplice.

    -   Le condizioni per una distribuzione binomiale sono soddisfatte:

        -   Numero fisso di prove indipendenti, probabilità constanti
            per ogni prova, solo due esiti per prova, "successo" o
            "fallimento"

    -   Le condizioni di approssimazione alla normalità sono tutte
        soddisfatte:

        -   $np \geq 5\  \cup nq \geq 5$

        -   Se sono soddisfatte, allora $\mu = np$ e
            $\sigma = \sqrt{npq}$

-   **Notazione**

    -   $n$ è la taglia campionaria

    -   $\widehat{p} = \frac{x}{n}$ è la proporzione campionaria

    -   $p$ è la proporzione della popolazione (in $H_{0}$)

    -   $q = 1 - p$

-   **Statistica di test per la verifica di un'ipotesi sulla
    proporzione:**

    -   $z = \frac{\widehat{p} - p}{\sqrt{\frac{pq}{n}}}$

-   Per il p-value e i valori critici, utilizziamo la **normale
    standard**.

#### Test di ipotesi per una **media**: σ nota

-   **Requisiti**

    -   Il campione è casuale semplice.

    -   σ è noto.

    -   Una o entrambe le condizioni di normalità sono soddisfatte:

        -   La popolazione ha una distribuzione normale o $n > 30$.

-   **Statistica di test per la verifica di un'ipotesi sulla media:**

    -   $z = \frac{\overline{x} - \mu}{\frac{\sigma}{\sqrt{n}}}$

-   Per il p-value e i valori critici utilizziamo la **normale
    standard**.

-   Per una media, il metodo dell'intervallo di confidenza è equivalente
    a quello del p-value e tradizionale.

#### Test di ipotesi per una **media**: σ non nota

-   **Requisiti**

    -   Il campione è casuale semplice.

    -   σ non è noto.

    -   Una o entrambe le condizioni di normalità sono soddisfatte:

        -   La popolazione ha una distribuzione normale o $n > 30$.

-   **Statistica di test per la verifica di un'ipotesi sulla media:**

    -   $t = \frac{\overline{x} - \mu}{\frac{s}{\sqrt{n}}}$

-   Per il p-value e i valori critici utilizziamo la **t di Student**
    con $n - 1$ gradi di libertà. Il p-value è difficile da calcolare
    manualmente. Utilizzare un software o una tabella del p-value.

-   Per una media, il metodo dell'intervallo di confidenza è equivalente
    a quello del p-value e tradizionale.

#### Test di ipotesi per la **deviazione standard** o la **varianza**

-   **Requisiti**

    -   Il campione è casuale semplice.

    -   La popolazione è distribuita normalmente. (Vale la regola della
        rigidità della normalità vista prima, dato che i metodi per la
        deviazione standard non sono robusti).

-   **Statistica di test per la verifica di un'ipotesi sulla SD:**

    -   $\chi^{2} = \frac{(n - 1)s^{2}}{\sigma^{2}}$

-   Per il p-value e i valori critici utilizziamo il χ quadro. L'uso di
    software è raccomandato.

# Capitolo 6 -- Inferenza per due campioni

Quando ci troviamo davanti a due campioni, e vogliamo confrontarli e
decidere se le loro differenze sono statisticamente significative, siamo
di fronte all'inferenza su due campioni. Questo tipo di statistica è
comunemente effettuato ad esempio negli studi clinici, dove si vuole
accertare sistematicamente che le differenze tra il gruppo placebo sono
diverse da quello trattato.

## Inferenza su due proporzioni

Quando verifichiamo un'ipotesi con due campioni su una proporzione
abbiamo i seguenti requisiti:

-   I due campioni casuali semplici considerati non hanno alcun tipo di
    relazione, cioè non sono **appaiati** tra di loro.

-   Per ciascuno dei due campioni, il numero di successi è almeno 5 e il
    numero di fallimenti è almeno 5.

Abbiamo queste notazioni per le proporzioni:

-   $p_{1}$ è la proporzione della popolazione 1, da dove è estratto il
    campione 1

-   $n_{1}$ è la taglia campionaria del campione 1

-   $x_{1}$ è il numero di successi nel campione 1

-   ${\widehat{p}}_{1} = \frac{x_{1}}{n_{1}}$ è la proporzione
    campionaria del campione 1

-   ${\widehat{q}}_{1} = 1 - {\widehat{p}}_{1}$

Notazioni del tutto analoghe sono per il campione 2. Notare che se un
test non esplicita tutti questi valori, quasi sicuramente possiamo
calcolarli con formule inverse dai dati forniti. Ricordiamo di
arrotondare in modo sensibile (non possiamo avere 112.23 persone).

Vedremo se l'affermazione $p_{1} = p_{2}$ è rifiutabile o meno, ma ci
occorrerà una stima aggregata del valore reale di $p$:

$$\overline{p} = \frac{x_{1} + x_{2}}{n_{1} + n_{2}}$$

$$\overline{q} = 1 - \overline{p}$$

Questo valore prende il nome di **stima cumulata**.

Possiamo ora vedere la statistica di test utilizzando come
$H_{0}:p_{1} = p_{2}$ è $H_{1}:p_{1} \neq p_{2}$:

$$z = \frac{\left( {\widehat{p}}_{1} - {\widehat{p}}_{2} \right) - \left( p_{1} - p_{2} \right)}{\sqrt{\frac{\overline{pq}}{n_{1}} + \frac{\overline{pq}}{n_{2}}}}$$

Dato che consideriamo l'ipotesi nulla come vera, allora
$p_{1} - p_{2} = 0$. Per il p-value e i valori critici utilizziamo un
software o una tabella. Il procedimento per il test a due campioni è
pressoché identico a quello ad un singolo valore.

Possiamo anche procedere con il metodo dell'intervallo di confidenza. In
questo caso l'intervallo di confidenza è definito in questo modo:

$$\left( {\widehat{p}}_{1} - {\widehat{p}}_{2} \right) - E < {(p}_{1} - p_{2}) < {(\widehat{p}}_{1} - {\widehat{p}}_{2}) + E$$

$$E = z_{\frac{\alpha}{2}}\sqrt{\frac{{\widehat{p}}_{1}{\widehat{q}}_{1}}{n_{1}} + \frac{{\widehat{p}}_{2}{\widehat{q}}_{2}}{n_{2}}}$$

## Inferenza su due medie: campioni indipendenti

Vediamo ora come verificare ipotesi per la differenza di due medie
campionarie indipendenti. Definiamo intanto cosa si intende per campioni
**dipendenti** ed **indipendenti**:

Due campioni sono **dipendenti** se gli elementi di un campione possono
essere utilizzati per determinare in qualche modo l'altro. La dipendenza
può anche essere temporale: stessi soggetti osservati prima del
trattamento e dopo il trattamento. Due campioni sono **indipendenti** se
non sono legati in alcun modo.

Per due campioni indipendenti abbiamo i seguenti requisiti:

-   I due campioni sono **indipendenti**.

-   Entrambi i campioni sono **casuali semplici**.

-   Le condizioni di normalità sono rispettate per entrambi i campioni:
    la popolazione di partenza è normale o la taglia campionaria di
    entrambi i campioni è \> 30. Questo test è comunque robusto.

Verifica di ipotesi per due medie di campioni indipendenti:

$$t = \frac{\left( {\overline{x}}_{1} - {\overline{x}}_{2} \right) - \left( \mu_{1} - \mu_{2} \right)}{\sqrt{\frac{s_{1}^{2}}{n_{1}} - \frac{s_{2}^{2}}{n_{2}}}}$$

Per ricercare i gradi di libertà, manualmente possiamo usare il valore
più grande tra $n_{1} - 1$ e $n_{2} - 1$, ma un metodo più preciso è
utilizzato dai calcolatori:

$$gl = \frac{(A + B)^{2}}{\frac{A^{2}}{n_{1} - 1} + \frac{B^{2}}{n_{2} - 1}}$$

$$\text{Dove}:\ \ \ \ \ \ \ A = \frac{s_{1}^{2}}{n_{1}}\ \ \ \ \ \ \text{e}\ \ \ \ \ \ B = \frac{s_{2}^{2}}{n_{2}}$$

Il P-value e i valori critici sono entrambi calcolati con la funzione t
di Student, e calcolati con tabelle o calcolatori. In questo caso, dato
che gli intervalli di confidenza utilizzano la stessa distribuzione e lo
stesso errore standard, l'utilizzo come test degli intervalli di
confidenza è equivalente ai metodi tradizionali e del P-value.

L'intervallo di confidenza si calcola come segue:

$$\left( {\overline{x}}_{1} - {\overline{x}}_{2} \right) - E < \mu_{1} - \mu_{2} < \left( {\overline{x}}_{1} - {\overline{x}}_{2} \right) + E$$

$$E = t_{\frac{\alpha}{2}}\sqrt{\frac{s_{1}^{2}}{n_{1}} + \frac{s_{2}^{2}}{n_{2}}}$$

E i gradi di libertà sono calcolati come descritto prima.

Possiamo utilizzare le espressioni viste prima dato che, se i requisiti
sono soddisfatti, allora la distribuzione campionaria di
${\overline{x}}_{1} - {\overline{x}}_{2}$ è approssimabile ad una t di
Student, con media pari a $\mu_{1} - \mu_{2}$ e deviazione standard
uguale a $\sqrt{\frac{s_{1}^{2}}{n_{1}} + \frac{s_{2}^{2}}{n_{2}}}$,
sfruttando la proprietà per cui la varianza della differenza di due
variabili aleatorie indipendenti è uguale alla somma delle varianze
delle due variabili. Esistono anche metodi per trovare la statistica di
test se $\sigma_{1}$ e $\sigma_{2}$ sono note, o se, per qualche motivo,
possiamo dire che $\sigma_{1} =$ $\sigma_{2}$. Questa uguaglianza è
assai difficile da dimostrare, e quindi il metodo che la richiede è
caldamente sconsigliato e non sarà mostrato qui.

$\mathbf{\sigma}_{\mathbf{1}}$ **e** $\mathbf{\sigma}_{\mathbf{2}}$
**sono note:** usiamo la normale standard al posto della t di Student.

$$z = \frac{\left( {\overline{x}}_{1} - {\overline{x}}_{2} \right) - \left( \mu_{1} - \mu_{2} \right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}} - \frac{\sigma_{2}^{2}}{n_{2}}}}$$

Intervallo di confidenza:

$$\left( {\overline{x}}_{1} - {\overline{x}}_{2} \right) - E < \mu_{1} - \mu_{2} < \left( {\overline{x}}_{1} - {\overline{x}}_{2} \right) + E$$

$$E = z_{\frac{\alpha}{2}}\sqrt{\frac{\sigma_{1}^{2}}{n_{1}} + \frac{\sigma_{2}^{2}}{n_{2}}}$$

## Inferenza su differenze per campioni appaiati

Ora vediamo come comportarci se i campioni sono in qualche modo
correlato tra loro, cioè **dipendenti**. Possiamo utilizzare questi
metodi per qualsiasi differenza, anche per la differenza di medie vista
prima. I requisiti sono:

-   Il campione consiste in coppie appaiate.

-   I campioni sono casuali semplici.

-   Le condizioni di normalità sono rispettate per entrambi i campioni:
    la popolazione di partenza è normale o la taglia campionaria di
    entrambi i campioni è \> 30. Questo test non è particolarmente
    robusto: se i dati variano molto dalla distribuzione normale, è bene
    utilizzare un metodo non parametrico.

Annotiamo in questo modo i simboli:

-   $d$ è la singola differenza dei valori di una coppia.

-   $\mu_{d}$ è il valore medio delle differenze $d$ per la popolazione
    di tutte le coppie appaiate

-   $\overline{d}$ è il valore medio delle differenze $d$ per i campioni
    appaiati

-   $s_{d}$ è la deviazione standard campionaria delle differenze $d$.

-   $n$ è il numero di coppie di dati

La statistica di test usa la t di Student:

$$t = \frac{\overline{d} - \mu_{d}}{\frac{s_{d}}{n}}$$

Dove i gradi di libertà sono $n - 1$. Per il p-value e i valori critici
usiamo la t di Student con una tabella o un software.

Per gli intervalli di confidenza delle coppie appaiate usiamo:

$$\overline{d} - E < \mu_{d} < \overline{d} + E$$

$$E = t_{a/2}\frac{s_{d}}{\sqrt{n}}$$

Per i valori critici di $t_{a/2}$ usiamo la tabella o un software.

## Confronto della variabilità in due campioni

La procedura è formulata per le varianze, ma possiamo utilizzare questo
metodo anche per le deviazioni standard (ricordiamo che le varianze sono
il quadrato delle deviazioni standard). I simboli sono quelli già
utilizzati.

-   Requisiti

    -   Le due popolazioni sono **indipendenti** tra loro.

    -   Le due popolazioni sono **distribuite normalmente**. Questo
        metodo è estremamente fragile.

-   Notazione particolare:

    -   $s_{1}^{2}$ è la **maggiore** varianza campionaria

    -   $n_{1}$ è la taglia del campione con varianza **maggiore**.

    -   $\sigma_{1}^{2}$ è la varianza della popolazione dalla quale il
        campione con varianza **maggiore** è stato estratto.

    -   $s_{2}^{2},\ n_{2},\ \text{e}\ \sigma_{1}^{2}$ sono analoghe a
        riferite all'altro campione e all'altra popolazione.

-   Statistica di test:

$$F = \frac{s_{1}^{2}}{s_{2}^{2}}$$

-   Notiamo che si usa la distribuzione F, simile al $\chi^{2}$, ma che
    dipende da due gradi di libertà, quello del numeratore ($n_{1} - 1$)
    e del denominatore ($n_{2} - 1$). Con il grafico della distribuzione
    F, vediamo che come il $\chi^{2}$ anche essa è asimmetrica, non è
    mai negativa, e si avvicina alla normale mentre i due gradi di
    libertà si avvicinano all'infinito.

-   L'utilizzo di un software elimina la difficile interpretazione della
    distribuzione F dandoci subito i valori critici o meglio il P-value.

# Capitolo 7 -- Correlazione e regressione

In questo capitolo ci occupiamo di determinare se c'è una qualche
associazione tra due variabili, e, se questa esiste, come descriverla
attraverso un'equazione matematica. La correlazione è studiata
attraverso un grafico, lo scatterplot, e attraverso un coefficiente
detto **coefficiente di correlazione lineare**, una misura numerica del
gradodi correlazione delle due variabili.

Lo scatterplot può darci l'idea di cosa intendiamo per correlazione, e
anche una preliminare ipotesi sulla possibile correlazione che due
variabili hanno prima di passare alle formule matematiche:

![](media/image9.jpeg){width="3.9075142169728783in"
height="4.87457895888014in"}Se da un'analisi preliminare con uno
scatterplot notiamo una qualche correlazione, possiamo calcolare il
coefficiente di correlazione. Il **coefficiente di correlazione lineare
di Pearson** è utilizzato per quantizzare quanto sono correlati, in modo
lineare, due set di dati. Se viene calcolato con dati campionari, il
coefficiente è denominato $r$; se è calcolato con tutti i dati della
popolazione è denominato con la lettera greca $\rho$ (Rho).

Il coefficiente di correlazione lineare può essere sempre calcolato, ma
può non aver significato se il campione è raccolto male o i dati non
hanno significato; se lo scatterplot non fa notare una correlazione
lineare o se ci sono outlier.

Più formalmente, potremmo dire che le coppie di dati devono provenire da
una **distribuzione normale bivariata**, cioè ad ogni valore fissato di
$x$, i valori di $y$ seguono una distribuzione normale, e viceversa.

Elenchiamo alcuni simboli utilizzati nelle prossime formule:

-   $n$ è il numero delle coppie di dati possibili,

-   $\sum_{}^{}x$ indica la sommatoria di tutti i valori di $x$,

-   $\sum_{}^{}x^{2}$ indica la sommatoria di tutti i valori di $x$
    **dopo** averli elevati al quadrato,

-   $\left( \sum_{}^{}x \right)^{2}$ indica la sommatoria di tutti i
    valori di $x$, **poi** li si eleva al quadrato. È estremamente
    importante non confondere le due scritture.

-   $\sum_{}^{}{xy}$ indica la sommatoria di tutti i prodotti $xy$.

-   $r$ è il coefficiente di relazione lineare riferito ad un campione,

-   $\rho$ è il coefficiente di relazione lineare riferito alla
    popolazione.

Possiamo calcolare il coefficiente $r$ con la seguente formula:\
$$r = \frac{n\sum_{}^{}{xy} - (\sum_{}^{}x)(\sum_{}^{}y)}{\sqrt{n\left( \sum_{}^{}x^{2} \right) - \left( \sum_{}^{}x \right)^{2}}*\sqrt{n\left( \sum_{}^{}y^{2} \right) - \left( \sum_{}^{}y \right)^{2}}}$$

Il valore di $r$ può essere interpretato con una tabella, oppure
attraverso il p-value. Il p-value è ottenuto spesso da software, ed è
interpretato in un modo identico a come abbiamo visto prima ($H_{0}$ è
rifiutato se p-value \> $\alpha$, dove α è fissato *a priori*).

Il coefficiente di Pearson ha delle caratteristiche particolari:

-   Il valore di $r$ è sempre compreso tra gli estremi, inclusi, di +1 e
    -1.

-   Il valore di $r$ non cambia se tutti i valori di entrambe le
    variabili $x\ \text{e}\ y$ sono convertiti in una scala differente.

-   Il valore di $r$ non dipende dall'ordine in cui vengono scelte $x$
    ed $y$: scambiando i valori tra le due variabili il valore di $r$
    non cambia.

-   $r$ misura l'intensità di un'associazione lineare, ma non è in grado
    di misurare l'intensità di associazioni non lineari.

Possiamo utilizzare un test di ipotesi per vedere se c'è o meno una
correlazione lineare tra due popolazioni, cioè se $\rho = 0$ o
$\rho \neq 0$. Procediamo come abbiamo fatto per tutti gli altri test di
ipotesi:

-   **Metodo 1: la statistica di test è** $\mathbf{t}$

    -   Statistica di Test:

> $$t = \frac{r}{\sqrt{\frac{1 - r^{2}}{n - 2}}}$$

-   Valori critici e P-value sono calcolati con un numero di gradi di
    libertà pari ad $n - 2$.

-   Per trarre le nostre conclusioni possiamo dire che se
    $|t| > valore\ critico$, allora rifiutiamo $H_{0}$ e possiamo dire
    che c'è evidenza statistica per una correlazione lineare. Se invece
    $|t| < valore\ critico$, allora non possiamo rifiutare $H_{0}$, e
    non c'è evidenza di correlazione lineare.

```{=html}
<!-- -->
```
-   **Metodo 2: utilizzo di** $\mathbf{r}$ **come statistica di test**

    -   Possiamo utilizzare direttamente i valori di $r$ per vedere se
        c'è correlazione o meno. Utilizziamo una tabella particolare dei
        valori critici di $r$, e traiamo le nostre considerazioni in
        modo uguale a prima.

Per testare se c'è una correlazione lineare **positiva** o **negativa**,
il test diventa ad una coda sola: dobbiamo modificare α in maniera
opportuna, e modificare le nostre ipotesi per avere $H_{0}:\rho = 0$ e
$H_{1}:\rho < 0$ per una correlazione negativa e $H_{1}:\rho > 0$ per
una correlazione positiva.

## La regressione

Ora vogliamo prendere due variabili in correlazione lineare e descrivere
matematicamente una retta, chiamata **retta di regressione**, che
descrive la relazione delle due variabili. L'equazione che definisce
questa retta è chiamata **equazione di regressione**.

Assoceremo la variabile $x$, chiamata **variabile indipendente**, con
l'altra variabile $y$, chiamata **variabile dipendente**. L'equazione
tipica di una retta è $y = mx + b$. Noi utilizzeremo la stessa forma,
scritta come $\widehat{y} = b_{1}x + b_{0}$. $b_{1}\ \text{e}\ b_{0}$
sono notazioni riferite al campione, mentre
$\beta_{1}\ \text{e}\ \beta_{2}$ sono riferite alla popolazione.
Possiamo stimare i valori della popolazione partendo dai valori del
campione, come vedremo dopo.

Anche qui possiamo sempre creare la retta di regressione lineare, ma è
bene considerare che questa può non avere senso se i seguenti requisiti
non sono soddisfatti:

-   Il campione è formato da dati quantitativi, e questi sono raccolti
    in modo corretto,

-   L'esame visivo dello scatterplot mostra della linearità,

-   Non ci sono outlier, o gli outlier sono considerati in maniera
    opportuna.

Il metodo è comunque robusto.

La **pendenza** è calcolata come:

$$b_{1} = \frac{n\left( \sum_{}^{}{xy} \right) - (\sum_{}^{}x)(\sum_{}^{}y)}{n\left( \sum_{}^{}x^{2} \right) - (\sum_{}^{}x)}$$

E l'**intercetta** come:

$$b_{0} = \overline{y} - b_{1}\overline{x}$$

La retta descritta dall'equazione $\widehat{y} = b_{0} + b_{1}x$ è
quella che meglio interpola i dati delle due variabili.

Possiamo utilizzare la retta di regressione per predire i valori di una
variabile quando non sono noti i valori dell'altra variabile. Prendiamo
ad esempio l'uso della legge di Lambert-Beer per predire le
concentrazioni. Se non c'è relazione tra le due variabili, la migliore
stima per predire un qualsiasi valore di $y$ è la sua media campionaria,
$\overline{y}$. Se c'è correlazione con un\'altra variabile $x$, la
migliore stima diventa il valore di $y$ che si trova sostituendo
nell'equazione di regressione il valore di $x$ associato alla $y$
incognita.

Ricordiamo che la retta è utilizzabile solo se c'è una vera correlazione
tra le due variabili, cioè se $r$ è significativo. Occorre quindi sempre
fare un test di ipotesi per controllare se $r$ è significativo.

## Valori anomali e punti influenti. Minimi scarti quadrati

In uno scatterplot, possiamo definire i cosiddetti **punti influenti**
come i punti che influiscono pesantemente sulla retta di regressione
calcolata come prima. Possiamo inoltre avere **valori anomali**, cioè
valori che si discostano tanto da tutti gli altri (e quindi dalla retta
di regressione).

I punti influenti si trovano togliendo il punto pensato influente e
ricalcolando la retta. I valori anomali sono facilmente visibili in uno
scatterplot, e non sono molto diversi dagli **outlier**.

La retta che meglio descrive un set di dati è quella che porta ad avere
meno **residui** tra di essa e i punti. I residui sono calcolati da
ciascun punto con la differenza $y - \widehat{y}$, dove $\widehat{y}$ è
il valore predetto di $y$ dalla retta lineare. I **minimi quadrati**
sono i quadrati più piccoli che si possono costruire con lato uguale a
ciascuno dei residui. La retta che descrive meglio il set di dati è la
retta che produce i minimi quadrati:

$$minimi\ quadrati = \sum_{}^{}\left( y - \widehat{y} \right)^{2}$$

Il **grafico dei residui** è il grafico che otteniamo sostituendo le $y$
dello scatterplot con i residui corrispondenti. L'equazione della retta
descrive bene i punti se il grafico degli scarti non presenta alcuna
distribuzione se non quella completamente casuale.

Chiamiamo **deviazione totale** dalla media il valore
$(y - \overline{y})$.\
Chiamiamo **deviazione spiegata** il valore
$(\widehat{y} - \overline{y})$.\
Chiamiamo **deviazione non spiegata** il valore ($y - \widehat{y}$).

Notiamo che il valore di correlazione lineare $r$ è anche definito come:

$$r^{2} = \frac{deviazione\ spiegata}{deviazione\ totale}$$

# Capitolo 8 -- Analisi della varianza. Metodo ANOVA

Vorremmo ora introdurre un test statistico per verificare l'ipotesi che
medie di tre o più popolazioni sono uguali. In questo caso,
$H_{0}:\ \mu_{1} = \mu_{2} = \mu_{3} = \ldots = \mu_{n}$ e
$H_{1}:\ \text{almeno\ una\ di\ queste\ uguaglianze\ non\ è\ vera}$.

Non possiamo effettuare un test per ogni coppia di variabili dato che la
confidenza, in questo caso, scende esponenzialmente al pari passo
dell'aumentare dei numeri di test che dobbiamo eseguire.

Il metodo **ANOVA** (**AN**alysis **O**f **VA**riance) è usato per
testare questa ipotesi. Esso utilizza la distribuzione F, già stata
introdotta. L'analisi si basa sul confronto delle varianze stimate per
ciascuna popolazione, e queste stime saranno definite più avanti.

Parliamo di ANOVA ad *una via* se le nostre popolazioni sono
diversificate da un solo fattore (o "via"). Ad esempio, in un
esperimento potremmo dividere dei campi coltivati in "non trattati",
"pesticidi" e "coccinelle", per il fattore "trattamento": in questo caso
si utilizza il metodo ANOVA ad una via.\
Parliamo di ANOVA a *due vie* se le nostre popolazioni sono
diversificate per due fattori diversi, ad esempio il fattore
"trattamento" come prima, e il fattore "irrigazione" che può essere
"irrigato" o "non irrigato".

Un fattore o via, quindi, è una proprietà, caratteristica o comunque una
tipologia che ci permette di distinguere una popolazione dall'altra.

## ANOVA ad una via

I calcoli per il metodo ANOVA sono molto complessi, ma ricordiamo:

-   $H_{0}:\ \mu_{1} = \mu_{2} = \mu_{3} = \ldots = \mu_{n}$ e
    $H_{1}:\ \text{almeno\ una\ di\ queste\ uguaglianze\ non\ è\ vera}$.

-   Un p-value molto piccolo (minore di α), porta al rifiuto di $H_{0}$.
    Il contrario porta al non rifiutare $H_{0}$.

I requisiti per il metodo ANOVA sono abbastanza lassi, dato che il
metodo è molto robusto, ma comunque sono elencabili:

-   La popolazione è distribuita normalmente.

-   Le popolazioni hanno la stessa varianza $\sigma^{2}$.

-   I campioni sono campioni casuali semplici e i dati sono
    quantitativi.

-   I campioni sono indipendenti gli uni dagli altri.

La procedura è necessariamente seguita utilizzando un software che
produce un p-value, interpretato nella via consueta. Notare che il test
ANOVA non ci da l'uguaglianza di tutte le medie ad un valore, ma solo
che le medie sono uguali. Per ottenere quel numero, sono necessari altri
test. Perché il test ANOVA funziona? Molto probabilmente è magico.
